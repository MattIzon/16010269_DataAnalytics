{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNrGqphp5vRp/hlwrZ0xJAj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MattIzon/16010269_DataAnalytics/blob/main/DNN/Model1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression Model District 1\n",
        "\n",
        "Predictors:\n",
        "*   day_of_week\n",
        "*   temp\n",
        "*   sndp\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_364iE3AwpA-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J9vp7tzGf3eA"
      },
      "outputs": [],
      "source": [
        "# Set-up\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "def normalise(df, column_list):\n",
        "  # Normalises df columns in column_list returning a dictionary of column_name: (min_value, max_value) that can be used to recover the original values\n",
        "  params = dict()\n",
        "\n",
        "  for col in column_list:\n",
        "    min = df[col].min()\n",
        "    max = df[col].max()\n",
        "    params[col] = (min, max)\n",
        "    df[col] = (df[col] - min) / (max - min)\n",
        "\n",
        "  return params\n",
        "\n",
        "\n",
        "def normalise_w_params(df, params, column_list):\n",
        "  # Normalises df columns using the provided params\n",
        "  for col in column_list:\n",
        "    min = params[col][0]\n",
        "    max = params[col][1]\n",
        "    df[col] = (df[col] - min) / (max - min)\n",
        "\n",
        "\n",
        "def denormalise(df, params, column_list):\n",
        "  # Uses the params dictionary produced during normalisation and a list of columns to recover their original values\n",
        "  for col in column_list:\n",
        "    min = params[col][0]\n",
        "    max = params[col][1]\n",
        "    df[col] = (df[col] * (max-min)) + min\n",
        "\n",
        "\n",
        "def flat_list(nested_list):\n",
        "  return [value for sublist in nested_list for value in sublist]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generic = pd.read_csv('https://raw.githubusercontent.com/MattIzon/16010269_DataAnalytics/main/LR/Districts/1/generic_set_district1.0.csv')"
      ],
      "metadata": {
        "id": "bs_BolkcBckJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Specific Code goes here"
      ],
      "metadata": {
        "id": "vfxwSyjzIadb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generic.corr()['crime_count']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6Ytyqvss1V9",
        "outputId": "8fded8b0-c81b-4178-e5d6-f5351a5a7b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "index                   0.163109\n",
              "day_of_week            -0.212150\n",
              "district                     NaN\n",
              "crime_count             1.000000\n",
              "mo                      0.162114\n",
              "temp                    0.260212\n",
              "dewp                    0.261973\n",
              "slp                    -0.144656\n",
              "stp                    -0.011257\n",
              "visib                   0.087582\n",
              "wdsp                   -0.081384\n",
              "mxpsd                  -0.042748\n",
              "gust                   -0.036088\n",
              "max                     0.247429\n",
              "min                     0.271675\n",
              "prcp                    0.037959\n",
              "sndp                   -0.228342\n",
              "fog                    -0.047208\n",
              "rain_drizzle            0.059003\n",
              "snow_ice_pellets       -0.136210\n",
              "hail                         NaN\n",
              "thunder                 0.069048\n",
              "tornado_funnel_cloud         NaN\n",
              "Name: crime_count, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['day_of_week', 'temp', 'sndp', 'crime_count']\n",
        "data = generic[columns]\n",
        "scale_params = normalise(data, columns)"
      ],
      "metadata": {
        "id": "y4jsaM5JzRIF",
        "outputId": "266af6a1-d096-412f-e610-aadb4d1b26ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seperate train / eval predictors / targets\n",
        "qty_predictors = 3\n",
        "qty_targets = 1\n",
        "train_size = int(len(data)*0.8)\n",
        "\n",
        "train_predictors = data.iloc[:train_size,0:qty_predictors]\n",
        "train_targets = data.iloc[:train_size,qty_predictors]\n",
        "\n",
        "eval_predictors = data.iloc[train_size:,0:qty_predictors]\n",
        "eval_targets = data.iloc[train_size:,qty_predictors]"
      ],
      "metadata": {
        "id": "Z2KCqEQpiMlT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Design model: layers ~ inputs -> h1 -> outputs\n",
        "h1 = 2\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(h1, input_shape=[qty_predictors], activation='sigmoid')) # h1\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) # output\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.01))\n",
        "\n",
        "\n",
        "# model = tf.keras.Sequential()\n",
        "# model.add(tf.keras.layers.Dense(qty_targets, input_shape=[qty_predictors], activation))\n",
        "# model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.01))"
      ],
      "metadata": {
        "id": "vjj8Be7yqkLH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVJsFwGFziXv",
        "outputId": "963cee31-dbc4-4893-dd95-1ffcebfafbe6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 2)                 8         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11\n",
            "Trainable params: 11\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "history = model.fit(train_predictors, train_targets, epochs=250)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2UP_cSK0QnO",
        "outputId": "5b14d18b-ad2e-47ca-af0d-bd16ae273dc4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "44/44 [==============================] - 1s 2ms/step - loss: 0.0485\n",
            "Epoch 2/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0361\n",
            "Epoch 3/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0356\n",
            "Epoch 4/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0351\n",
            "Epoch 5/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0347\n",
            "Epoch 6/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0343\n",
            "Epoch 7/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0339\n",
            "Epoch 8/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0336\n",
            "Epoch 9/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0333\n",
            "Epoch 10/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0331\n",
            "Epoch 11/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0330\n",
            "Epoch 12/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0328\n",
            "Epoch 13/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0328\n",
            "Epoch 14/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0327\n",
            "Epoch 15/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0327\n",
            "Epoch 16/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0327\n",
            "Epoch 17/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0327\n",
            "Epoch 18/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0326\n",
            "Epoch 19/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0327\n",
            "Epoch 20/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0326\n",
            "Epoch 21/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0326\n",
            "Epoch 22/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0326\n",
            "Epoch 23/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0326\n",
            "Epoch 24/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0325\n",
            "Epoch 25/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0325\n",
            "Epoch 26/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0324\n",
            "Epoch 27/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0325\n",
            "Epoch 28/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0327\n",
            "Epoch 29/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0327\n",
            "Epoch 30/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0324\n",
            "Epoch 31/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0325\n",
            "Epoch 32/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0325\n",
            "Epoch 33/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0326\n",
            "Epoch 34/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0324\n",
            "Epoch 35/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0324\n",
            "Epoch 36/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0325\n",
            "Epoch 37/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0324\n",
            "Epoch 38/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0325\n",
            "Epoch 39/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0324\n",
            "Epoch 40/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0324\n",
            "Epoch 41/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0324\n",
            "Epoch 42/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0324\n",
            "Epoch 43/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0324\n",
            "Epoch 44/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0324\n",
            "Epoch 45/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0325\n",
            "Epoch 46/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0325\n",
            "Epoch 47/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0323\n",
            "Epoch 48/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0323\n",
            "Epoch 49/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0324\n",
            "Epoch 50/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0324\n",
            "Epoch 51/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0323\n",
            "Epoch 52/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0324\n",
            "Epoch 53/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0322\n",
            "Epoch 54/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0323\n",
            "Epoch 55/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0324\n",
            "Epoch 56/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0324\n",
            "Epoch 57/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0323\n",
            "Epoch 58/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0323\n",
            "Epoch 59/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0325\n",
            "Epoch 60/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0323\n",
            "Epoch 61/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0323\n",
            "Epoch 62/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0321\n",
            "Epoch 63/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0323\n",
            "Epoch 64/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0323\n",
            "Epoch 65/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0322\n",
            "Epoch 66/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0323\n",
            "Epoch 67/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0322\n",
            "Epoch 68/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0323\n",
            "Epoch 69/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0323\n",
            "Epoch 70/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0322\n",
            "Epoch 71/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0322\n",
            "Epoch 72/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0323\n",
            "Epoch 73/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0323\n",
            "Epoch 74/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0321\n",
            "Epoch 75/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0321\n",
            "Epoch 76/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0321\n",
            "Epoch 77/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0321\n",
            "Epoch 78/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0321\n",
            "Epoch 79/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0320\n",
            "Epoch 80/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0320\n",
            "Epoch 81/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0320\n",
            "Epoch 82/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0320\n",
            "Epoch 83/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0320\n",
            "Epoch 84/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0321\n",
            "Epoch 85/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0320\n",
            "Epoch 86/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0319\n",
            "Epoch 87/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0319\n",
            "Epoch 88/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0319\n",
            "Epoch 89/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0319\n",
            "Epoch 90/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0321\n",
            "Epoch 91/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0320\n",
            "Epoch 92/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0318\n",
            "Epoch 93/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0319\n",
            "Epoch 94/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0319\n",
            "Epoch 95/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0318\n",
            "Epoch 96/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0317\n",
            "Epoch 97/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0317\n",
            "Epoch 98/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0318\n",
            "Epoch 99/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0317\n",
            "Epoch 100/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0318\n",
            "Epoch 101/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0318\n",
            "Epoch 102/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0319\n",
            "Epoch 103/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0318\n",
            "Epoch 104/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0317\n",
            "Epoch 105/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0317\n",
            "Epoch 106/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0316\n",
            "Epoch 107/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0316\n",
            "Epoch 108/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0317\n",
            "Epoch 109/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0314\n",
            "Epoch 110/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0315\n",
            "Epoch 111/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0314\n",
            "Epoch 112/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0315\n",
            "Epoch 113/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0314\n",
            "Epoch 114/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0314\n",
            "Epoch 115/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0314\n",
            "Epoch 116/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0314\n",
            "Epoch 117/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0314\n",
            "Epoch 118/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0314\n",
            "Epoch 119/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0315\n",
            "Epoch 120/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0314\n",
            "Epoch 121/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0314\n",
            "Epoch 122/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0314\n",
            "Epoch 123/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0313\n",
            "Epoch 124/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0313\n",
            "Epoch 125/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0314\n",
            "Epoch 126/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0313\n",
            "Epoch 127/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0313\n",
            "Epoch 128/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0313\n",
            "Epoch 129/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0314\n",
            "Epoch 130/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0313\n",
            "Epoch 131/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0313\n",
            "Epoch 132/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0313\n",
            "Epoch 133/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0313\n",
            "Epoch 134/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0313\n",
            "Epoch 135/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0313\n",
            "Epoch 136/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 137/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0313\n",
            "Epoch 138/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0313\n",
            "Epoch 139/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 140/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0313\n",
            "Epoch 141/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0313\n",
            "Epoch 142/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 143/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 144/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 145/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 146/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0315\n",
            "Epoch 147/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0314\n",
            "Epoch 148/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0315\n",
            "Epoch 149/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 150/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 151/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0312\n",
            "Epoch 152/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0311\n",
            "Epoch 153/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0314\n",
            "Epoch 154/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0313\n",
            "Epoch 155/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 156/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 157/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 158/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0313\n",
            "Epoch 159/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 160/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0310\n",
            "Epoch 161/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0314\n",
            "Epoch 162/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0314\n",
            "Epoch 163/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0315\n",
            "Epoch 164/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 165/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 166/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 167/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 168/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 169/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 170/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 171/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 172/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 173/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0313\n",
            "Epoch 174/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0313\n",
            "Epoch 175/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 176/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0310\n",
            "Epoch 177/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0313\n",
            "Epoch 178/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0315\n",
            "Epoch 179/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 180/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0313\n",
            "Epoch 181/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 182/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 183/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 184/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 185/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0310\n",
            "Epoch 186/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 187/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 188/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 189/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0314\n",
            "Epoch 190/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0310\n",
            "Epoch 191/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 192/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 193/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0309\n",
            "Epoch 194/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0313\n",
            "Epoch 195/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 196/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 197/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 198/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 199/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 200/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 201/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0313\n",
            "Epoch 202/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 203/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0310\n",
            "Epoch 204/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 205/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0310\n",
            "Epoch 206/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0314\n",
            "Epoch 207/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0314\n",
            "Epoch 208/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 209/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 210/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 211/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 212/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 213/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 214/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 215/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 216/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 217/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 218/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 219/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0310\n",
            "Epoch 220/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0310\n",
            "Epoch 221/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 222/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0310\n",
            "Epoch 223/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 224/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 225/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0310\n",
            "Epoch 226/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 227/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0310\n",
            "Epoch 228/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 229/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0310\n",
            "Epoch 230/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 231/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0310\n",
            "Epoch 232/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 233/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 234/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0310\n",
            "Epoch 235/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "Epoch 236/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0313\n",
            "Epoch 237/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 238/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 239/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 240/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 241/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0310\n",
            "Epoch 242/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0310\n",
            "Epoch 243/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 244/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 245/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0310\n",
            "Epoch 246/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0310\n",
            "Epoch 247/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0310\n",
            "Epoch 248/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0310\n",
            "Epoch 249/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 250/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View training history\n",
        "plt.plot(history.history['loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "e9wcugdS2zyM",
        "outputId": "6fd2f6a4-2999-4623-8b64-c005fbe1dad1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa967bcffd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test model\n",
        "eval_predictions = flat_list(model.predict(eval_predictors))"
      ],
      "metadata": {
        "id": "F3hcZ9wt31pC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse model quality vs mean \n",
        "rmse = np.sqrt(np.mean((eval_targets.values - eval_predictions)**2))\n",
        "print('LinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "avg = np.mean(train_targets)\n",
        "\n",
        "rmse = np.sqrt(np.mean((eval_targets.values - avg)**2))\n",
        "print('Using the training data mean of {0} would have has resulted in a RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iYPVeVC7KYR",
        "outputId": "28879421-ec12-4886-aa88-b5c13ffdfb24"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression has RMSE of 0.18950291531097307\n",
            "Using the training data mean of 0.5800811688311688 would have has resulted in a RMSE of 0.2056886171602519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "\n",
        "test = pd.read_csv('https://raw.githubusercontent.com/MattIzon/16010269_DataAnalytics/main/LR/Districts/1/test_set_district1.0.csv')\n",
        "test_predictors = test[columns[0:qty_predictors]]\n",
        "normalise_w_params(test_predictors, scale_params, columns[0:qty_predictors])\n",
        "\n",
        "test_predictions = pd.DataFrame(flat_list(model.predict(test_predictors)), columns=['crime_count'])\n",
        "denormalise(test_predictions, scale_params, ['crime_count'])\n",
        "test_targets = test[columns[qty_predictors]]\n",
        "\n",
        "results = pd.DataFrame()\n",
        "results['predicted'] = test_predictions\n",
        "results['actual'] = test_targets\n",
        "results['error_squared'] = (results['predicted'] - results['actual']) ** 2\n",
        "print(results)\n",
        "\n",
        "print('The RMSE on the 5 test values is {}.'.format(np.sqrt(np.mean(results.error_squared))))\n",
        "print()"
      ],
      "metadata": {
        "id": "jsSl4tvr2aNX",
        "outputId": "786e2d08-b300-4c75-f04f-2b04a9de464a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   predicted  actual  error_squared\n",
            "0  40.582371      42       2.009673\n",
            "1  42.797310      36      46.203422\n",
            "2  37.637554      44      40.480717\n",
            "3  42.119370      30     146.879117\n",
            "4  31.761345      22      95.283854\n",
            "The RMSE on the 5 test values is 8.134577836076815.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    }
  ]
}