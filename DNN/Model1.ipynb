{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPblUkFmL2bzOiv9f6tjR9+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MattIzon/16010269_DataAnalytics/blob/main/DNN/Model1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DNN Model 1 Districts Included\n",
        "\n",
        "Predictors Removed:\n",
        "*   date\n",
        "*   gust\n",
        "*   hail\n",
        "*   tornado_funnel_cloud\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_364iE3AwpA-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J9vp7tzGf3eA"
      },
      "outputs": [],
      "source": [
        "# Set-up\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "def normalise(df, column_list):\n",
        "  # Normalises df columns in column_list returning a dictionary of column_name: (min_value, max_value) that can be used to recover the original values\n",
        "  params = dict()\n",
        "\n",
        "  for col in column_list:\n",
        "    min = df[col].min()\n",
        "    max = df[col].max()\n",
        "    params[col] = (min, max)\n",
        "    df[col] = (df[col] - min) / (max - min)\n",
        "\n",
        "  return params\n",
        "\n",
        "\n",
        "def normalise_w_params(df, params, column_list):\n",
        "  # Normalises df columns using the provided params\n",
        "  for col in column_list:\n",
        "    min = params[col][0]\n",
        "    max = params[col][1]\n",
        "    df[col] = (df[col] - min) / (max - min)\n",
        "\n",
        "\n",
        "def denormalise(df, params, column_list):\n",
        "  # Uses the params dictionary produced during normalisation and a list of columns to recover their original values\n",
        "  for col in column_list:\n",
        "    min = params[col][0]\n",
        "    max = params[col][1]\n",
        "    df[col] = (df[col] * (max-min)) + min\n",
        "\n",
        "\n",
        "def flat_list(nested_list):\n",
        "  return [value for sublist in nested_list for value in sublist]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generic = pd.read_csv('https://raw.githubusercontent.com/MattIzon/16010269_DataAnalytics/main/DNN/DNN_generic_set.csv')"
      ],
      "metadata": {
        "id": "bs_BolkcBckJ"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Specific Code goes here"
      ],
      "metadata": {
        "id": "vfxwSyjzIadb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm = ['crime_count', 'temp', 'dewp', 'slp', 'stp', 'visib', 'wdsp', 'mxpsd', 'max', 'min', 'prcp', 'sndp', 'year']\n",
        "data = generic.drop(['date', 'gust', 'hail', 'tornado_funnel_cloud'], axis=1)\n",
        "\n",
        "# norm = ['crime_count', 'temp', 'slp', 'stp', 'visib', 'wdsp', 'mxpsd', 'prcp', 'sndp']\n",
        "# cols = ['crime_count', 'temp', 'slp', 'stp', 'visib', 'wdsp', 'mxpsd', 'prcp', 'sndp', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "# data = generic[cols]\n",
        "scale_params = normalise(data, norm)"
      ],
      "metadata": {
        "id": "y4jsaM5JzRIF"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data.columns)"
      ],
      "metadata": {
        "id": "dDnJA-Jp2t3X",
        "outputId": "256b7a68-70c6-4126-84d5-87cb55b8a106",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "FRXJadZL4oN-",
        "outputId": "2a893951-12ca-4d43-d614-dc380790befb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        crime_count          temp          dewp           slp           stp  \\\n",
              "count  39815.000000  39815.000000  39815.000000  39815.000000  39815.000000   \n",
              "mean       0.221713      0.653886      0.640334      0.456853      0.949347   \n",
              "std        0.083496      0.198255      0.187973      0.140349      0.156688   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.165517      0.496986      0.503457      0.365686      0.973759   \n",
              "50%        0.220690      0.660080      0.642081      0.448039      0.977869   \n",
              "75%        0.275862      0.834896      0.801778      0.542157      0.982078   \n",
              "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "              visib          wdsp         mxpsd           max           min  \\\n",
              "count  39815.000000  39815.000000  39815.000000  39815.000000  39815.000000   \n",
              "mean       0.898932      0.298549      0.316685      0.653899      0.650775   \n",
              "std        0.165857      0.154001      0.147970      0.211845      0.190256   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.871698      0.186084      0.203560      0.477627      0.512155   \n",
              "50%        0.981132      0.284790      0.300334      0.677288      0.651349   \n",
              "75%        1.000000      0.388350      0.404894      0.844746      0.816184   \n",
              "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "               prcp         sndp           fog  rain_drizzle  \\\n",
              "count  39815.000000  39815.00000  39815.000000  39815.000000   \n",
              "mean       0.030309      0.02594      0.045134      0.387668   \n",
              "std        0.071916      0.08970      0.207600      0.487224   \n",
              "min        0.000000      0.00000      0.000000      0.000000   \n",
              "25%        0.000000      0.00000      0.000000      0.000000   \n",
              "50%        0.000000      0.00000      0.000000      0.000000   \n",
              "75%        0.025163      0.00000      0.000000      1.000000   \n",
              "max        1.000000      1.00000      1.000000      1.000000   \n",
              "\n",
              "       snow_ice_pellets       thunder          year           Fri  \\\n",
              "count      39815.000000  39815.000000  39815.000000  39815.000000   \n",
              "mean           0.132990      0.124400      0.499799      0.142685   \n",
              "std            0.339568      0.330042      0.353576      0.349756   \n",
              "min            0.000000      0.000000      0.000000      0.000000   \n",
              "25%            0.000000      0.000000      0.250000      0.000000   \n",
              "50%            0.000000      0.000000      0.500000      0.000000   \n",
              "75%            0.000000      0.000000      0.750000      0.000000   \n",
              "max            1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "                Mon           Sat           Sun           Thu           Tue  \\\n",
              "count  39815.000000  39815.000000  39815.000000  39815.000000  39815.000000   \n",
              "mean       0.142986      0.142710      0.142735      0.142961      0.143187   \n",
              "std        0.350063      0.349781      0.349807      0.350038      0.350268   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "                Wed           Apr           Aug           Dec           Feb  \\\n",
              "count  39815.000000  39815.000000  39815.000000  39815.000000  39815.000000   \n",
              "mean       0.142735      0.082155      0.085068      0.085119      0.077031   \n",
              "std        0.349807      0.274604      0.278987      0.279062      0.266644   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "                Jan           Jul           Jun           Mar           May  \\\n",
              "count  39815.000000  39815.000000  39815.000000  39815.000000  39815.000000   \n",
              "mean       0.084842      0.084868      0.082230      0.084767      0.084742   \n",
              "std        0.278651      0.278688      0.274719      0.278538      0.278501   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "                Nov           Oct           Sep  district_1.0  district_2.0  \\\n",
              "count  39815.000000  39815.000000  39815.000000  39815.000000  39815.000000   \n",
              "mean       0.082055      0.084742      0.082381      0.009117      0.009167   \n",
              "std        0.274451      0.278501      0.274948      0.095049      0.095308   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "       district_3.0  district_4.0  district_5.0  district_6.0  district_7.0  \\\n",
              "count  39815.000000  39815.000000  39815.000000  39815.000000  39815.000000   \n",
              "mean       0.009017      0.009042      0.009042      0.009117      0.009017   \n",
              "std        0.094528      0.094659      0.094659      0.095049      0.094528   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "       district_8.0  district_9.0  district_10.0  district_11.0  \\\n",
              "count  39815.000000  39815.000000   39815.000000   39815.000000   \n",
              "mean       0.008992      0.009092       0.009167       0.009042   \n",
              "std        0.094398      0.094919       0.095308       0.094659   \n",
              "min        0.000000      0.000000       0.000000       0.000000   \n",
              "25%        0.000000      0.000000       0.000000       0.000000   \n",
              "50%        0.000000      0.000000       0.000000       0.000000   \n",
              "75%        0.000000      0.000000       0.000000       0.000000   \n",
              "max        1.000000      1.000000       1.000000       1.000000   \n",
              "\n",
              "       district_12.0  district_14.0  district_15.0  district_16.0  \\\n",
              "count   39815.000000   39815.000000   39815.000000   39815.000000   \n",
              "mean        0.009092       0.009117       0.009117       0.009017   \n",
              "std         0.094919       0.095049       0.095049       0.094528   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       0.000000   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "       district_17.0  district_18.0  district_19.0  district_20.0  \\\n",
              "count   39815.000000   39815.000000   39815.000000   39815.000000   \n",
              "mean        0.009092       0.009117       0.009042       0.009042   \n",
              "std         0.094919       0.095049       0.094659       0.094659   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       0.000000   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "       district_22.0  district_24.0  district_25.0  district_31.0  \n",
              "count   39815.000000   39815.000000   39815.000000   39815.000000  \n",
              "mean        0.009117       0.009142       0.009067       0.000176  \n",
              "std         0.095049       0.095178       0.094789       0.013258  \n",
              "min         0.000000       0.000000       0.000000       0.000000  \n",
              "25%         0.000000       0.000000       0.000000       0.000000  \n",
              "50%         0.000000       0.000000       0.000000       0.000000  \n",
              "75%         0.000000       0.000000       0.000000       0.000000  \n",
              "max         1.000000       1.000000       1.000000       1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-00a09547-f542-4a6b-9b18-aa0365f4665c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>crime_count</th>\n",
              "      <th>temp</th>\n",
              "      <th>dewp</th>\n",
              "      <th>slp</th>\n",
              "      <th>stp</th>\n",
              "      <th>visib</th>\n",
              "      <th>wdsp</th>\n",
              "      <th>mxpsd</th>\n",
              "      <th>max</th>\n",
              "      <th>min</th>\n",
              "      <th>prcp</th>\n",
              "      <th>sndp</th>\n",
              "      <th>fog</th>\n",
              "      <th>rain_drizzle</th>\n",
              "      <th>snow_ice_pellets</th>\n",
              "      <th>thunder</th>\n",
              "      <th>year</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>Apr</th>\n",
              "      <th>Aug</th>\n",
              "      <th>Dec</th>\n",
              "      <th>Feb</th>\n",
              "      <th>Jan</th>\n",
              "      <th>Jul</th>\n",
              "      <th>Jun</th>\n",
              "      <th>Mar</th>\n",
              "      <th>May</th>\n",
              "      <th>Nov</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>district_1.0</th>\n",
              "      <th>district_2.0</th>\n",
              "      <th>district_3.0</th>\n",
              "      <th>district_4.0</th>\n",
              "      <th>district_5.0</th>\n",
              "      <th>district_6.0</th>\n",
              "      <th>district_7.0</th>\n",
              "      <th>district_8.0</th>\n",
              "      <th>district_9.0</th>\n",
              "      <th>district_10.0</th>\n",
              "      <th>district_11.0</th>\n",
              "      <th>district_12.0</th>\n",
              "      <th>district_14.0</th>\n",
              "      <th>district_15.0</th>\n",
              "      <th>district_16.0</th>\n",
              "      <th>district_17.0</th>\n",
              "      <th>district_18.0</th>\n",
              "      <th>district_19.0</th>\n",
              "      <th>district_20.0</th>\n",
              "      <th>district_22.0</th>\n",
              "      <th>district_24.0</th>\n",
              "      <th>district_25.0</th>\n",
              "      <th>district_31.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.00000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "      <td>39815.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.221713</td>\n",
              "      <td>0.653886</td>\n",
              "      <td>0.640334</td>\n",
              "      <td>0.456853</td>\n",
              "      <td>0.949347</td>\n",
              "      <td>0.898932</td>\n",
              "      <td>0.298549</td>\n",
              "      <td>0.316685</td>\n",
              "      <td>0.653899</td>\n",
              "      <td>0.650775</td>\n",
              "      <td>0.030309</td>\n",
              "      <td>0.02594</td>\n",
              "      <td>0.045134</td>\n",
              "      <td>0.387668</td>\n",
              "      <td>0.132990</td>\n",
              "      <td>0.124400</td>\n",
              "      <td>0.499799</td>\n",
              "      <td>0.142685</td>\n",
              "      <td>0.142986</td>\n",
              "      <td>0.142710</td>\n",
              "      <td>0.142735</td>\n",
              "      <td>0.142961</td>\n",
              "      <td>0.143187</td>\n",
              "      <td>0.142735</td>\n",
              "      <td>0.082155</td>\n",
              "      <td>0.085068</td>\n",
              "      <td>0.085119</td>\n",
              "      <td>0.077031</td>\n",
              "      <td>0.084842</td>\n",
              "      <td>0.084868</td>\n",
              "      <td>0.082230</td>\n",
              "      <td>0.084767</td>\n",
              "      <td>0.084742</td>\n",
              "      <td>0.082055</td>\n",
              "      <td>0.084742</td>\n",
              "      <td>0.082381</td>\n",
              "      <td>0.009117</td>\n",
              "      <td>0.009167</td>\n",
              "      <td>0.009017</td>\n",
              "      <td>0.009042</td>\n",
              "      <td>0.009042</td>\n",
              "      <td>0.009117</td>\n",
              "      <td>0.009017</td>\n",
              "      <td>0.008992</td>\n",
              "      <td>0.009092</td>\n",
              "      <td>0.009167</td>\n",
              "      <td>0.009042</td>\n",
              "      <td>0.009092</td>\n",
              "      <td>0.009117</td>\n",
              "      <td>0.009117</td>\n",
              "      <td>0.009017</td>\n",
              "      <td>0.009092</td>\n",
              "      <td>0.009117</td>\n",
              "      <td>0.009042</td>\n",
              "      <td>0.009042</td>\n",
              "      <td>0.009117</td>\n",
              "      <td>0.009142</td>\n",
              "      <td>0.009067</td>\n",
              "      <td>0.000176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.083496</td>\n",
              "      <td>0.198255</td>\n",
              "      <td>0.187973</td>\n",
              "      <td>0.140349</td>\n",
              "      <td>0.156688</td>\n",
              "      <td>0.165857</td>\n",
              "      <td>0.154001</td>\n",
              "      <td>0.147970</td>\n",
              "      <td>0.211845</td>\n",
              "      <td>0.190256</td>\n",
              "      <td>0.071916</td>\n",
              "      <td>0.08970</td>\n",
              "      <td>0.207600</td>\n",
              "      <td>0.487224</td>\n",
              "      <td>0.339568</td>\n",
              "      <td>0.330042</td>\n",
              "      <td>0.353576</td>\n",
              "      <td>0.349756</td>\n",
              "      <td>0.350063</td>\n",
              "      <td>0.349781</td>\n",
              "      <td>0.349807</td>\n",
              "      <td>0.350038</td>\n",
              "      <td>0.350268</td>\n",
              "      <td>0.349807</td>\n",
              "      <td>0.274604</td>\n",
              "      <td>0.278987</td>\n",
              "      <td>0.279062</td>\n",
              "      <td>0.266644</td>\n",
              "      <td>0.278651</td>\n",
              "      <td>0.278688</td>\n",
              "      <td>0.274719</td>\n",
              "      <td>0.278538</td>\n",
              "      <td>0.278501</td>\n",
              "      <td>0.274451</td>\n",
              "      <td>0.278501</td>\n",
              "      <td>0.274948</td>\n",
              "      <td>0.095049</td>\n",
              "      <td>0.095308</td>\n",
              "      <td>0.094528</td>\n",
              "      <td>0.094659</td>\n",
              "      <td>0.094659</td>\n",
              "      <td>0.095049</td>\n",
              "      <td>0.094528</td>\n",
              "      <td>0.094398</td>\n",
              "      <td>0.094919</td>\n",
              "      <td>0.095308</td>\n",
              "      <td>0.094659</td>\n",
              "      <td>0.094919</td>\n",
              "      <td>0.095049</td>\n",
              "      <td>0.095049</td>\n",
              "      <td>0.094528</td>\n",
              "      <td>0.094919</td>\n",
              "      <td>0.095049</td>\n",
              "      <td>0.094659</td>\n",
              "      <td>0.094659</td>\n",
              "      <td>0.095049</td>\n",
              "      <td>0.095178</td>\n",
              "      <td>0.094789</td>\n",
              "      <td>0.013258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.165517</td>\n",
              "      <td>0.496986</td>\n",
              "      <td>0.503457</td>\n",
              "      <td>0.365686</td>\n",
              "      <td>0.973759</td>\n",
              "      <td>0.871698</td>\n",
              "      <td>0.186084</td>\n",
              "      <td>0.203560</td>\n",
              "      <td>0.477627</td>\n",
              "      <td>0.512155</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.220690</td>\n",
              "      <td>0.660080</td>\n",
              "      <td>0.642081</td>\n",
              "      <td>0.448039</td>\n",
              "      <td>0.977869</td>\n",
              "      <td>0.981132</td>\n",
              "      <td>0.284790</td>\n",
              "      <td>0.300334</td>\n",
              "      <td>0.677288</td>\n",
              "      <td>0.651349</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.275862</td>\n",
              "      <td>0.834896</td>\n",
              "      <td>0.801778</td>\n",
              "      <td>0.542157</td>\n",
              "      <td>0.982078</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.388350</td>\n",
              "      <td>0.404894</td>\n",
              "      <td>0.844746</td>\n",
              "      <td>0.816184</td>\n",
              "      <td>0.025163</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00a09547-f542-4a6b-9b18-aa0365f4665c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-00a09547-f542-4a6b-9b18-aa0365f4665c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-00a09547-f542-4a6b-9b18-aa0365f4665c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seperate train / eval predictors / targets\n",
        "qty_predictors = len(data.columns) - 1\n",
        "qty_targets = 1\n",
        "train_size = int(len(data)*0.8)\n",
        "\n",
        "train_predictors = data.iloc[:train_size,1:]\n",
        "train_targets = data.iloc[:train_size,0]\n",
        "\n",
        "eval_predictors = data.iloc[train_size:,1:]\n",
        "eval_targets = data.iloc[train_size:,0]"
      ],
      "metadata": {
        "id": "Z2KCqEQpiMlT"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Design model: layers ~ inputs(61) ->  h1(30) -> outputs(1)\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Input(shape = (qty_predictors,)))\n",
        "model.add(tf.keras.layers.Dense(30, activation='sigmoid')) # h1\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.0001))\n",
        "\n",
        "\n",
        "# model = tf.keras.Sequential()\n",
        "# model.add(tf.keras.layers.Dense(qty_targets, input_shape=[qty_predictors], activation))\n",
        "# model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.01))"
      ],
      "metadata": {
        "id": "vjj8Be7yqkLH"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVJsFwGFziXv",
        "outputId": "8d7bba75-0fdd-4f3a-d0cd-edb4fa9f8710"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_47 (Dense)            (None, 30)                1770      \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,801\n",
            "Trainable params: 1,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "history = model.fit(train_predictors, train_targets, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2UP_cSK0QnO",
        "outputId": "9bc57f09-3a0c-4630-fe72-e662fb9d2048"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "996/996 [==============================] - 2s 2ms/step - loss: 0.0080\n",
            "Epoch 2/10\n",
            "996/996 [==============================] - 2s 2ms/step - loss: 0.0066\n",
            "Epoch 3/10\n",
            "996/996 [==============================] - 2s 2ms/step - loss: 0.0064\n",
            "Epoch 4/10\n",
            "996/996 [==============================] - 2s 2ms/step - loss: 0.0063\n",
            "Epoch 5/10\n",
            "996/996 [==============================] - 2s 2ms/step - loss: 0.0063\n",
            "Epoch 6/10\n",
            "996/996 [==============================] - 2s 2ms/step - loss: 0.0063\n",
            "Epoch 7/10\n",
            "996/996 [==============================] - 2s 2ms/step - loss: 0.0062\n",
            "Epoch 8/10\n",
            "996/996 [==============================] - 2s 2ms/step - loss: 0.0062\n",
            "Epoch 9/10\n",
            "996/996 [==============================] - 2s 2ms/step - loss: 0.0062\n",
            "Epoch 10/10\n",
            "996/996 [==============================] - 2s 2ms/step - loss: 0.0062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View training history\n",
        "plt.plot(history.history['loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "e9wcugdS2zyM",
        "outputId": "ddb8e8f9-bd40-408d-d35d-8528d17b645f"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2b6d1f6a10>]"
            ]
          },
          "metadata": {},
          "execution_count": 160
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test model\n",
        "eval_predictions = flat_list(model.predict(eval_predictors))"
      ],
      "metadata": {
        "id": "F3hcZ9wt31pC"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse model quality vs mean \n",
        "rmse = np.sqrt(np.mean((eval_targets.values - eval_predictions)**2))\n",
        "print('LinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "avg = np.mean(train_targets)\n",
        "\n",
        "rmse = np.sqrt(np.mean((eval_targets.values - avg)**2))\n",
        "print('Using the training data mean of {0} would have has resulted in a RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iYPVeVC7KYR",
        "outputId": "ff634c32-b6cd-42dc-876c-b55f732180e4"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression has RMSE of 0.0794012246700777\n",
            "Using the training data mean of 0.22161635495199783 would have has resulted in a RMSE of 0.08379558968638116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "\n",
        "test = pd.read_csv('https://raw.githubusercontent.com/MattIzon/16010269_DataAnalytics/main/DNN/DNN_test_set.csv')\n",
        "test.drop(['date', 'gust', 'hail', 'tornado_funnel_cloud'], axis=1, inplace=True)\n",
        "test_predictors = test.iloc[:,1:]\n",
        "normalise_w_params(test_predictors, scale_params, norm[1:])\n",
        "\n",
        "test_predictions = pd.DataFrame(flat_list(model.predict(test_predictors)), columns=['crime_count'])\n",
        "denormalise(test_predictions, scale_params, ['crime_count'])\n",
        "test_targets = test['crime_count']\n",
        "\n",
        "results = pd.DataFrame()\n",
        "results['predicted'] = test_predictions\n",
        "results['actual'] = test_targets\n",
        "results['error_squared'] = (results['predicted'] - results['actual']) ** 2\n",
        "print(results)\n",
        "\n",
        "print('The RMSE on the test values is {}.'.format(np.sqrt(np.mean(results.error_squared))))\n",
        "print()"
      ],
      "metadata": {
        "id": "jsSl4tvr2aNX",
        "outputId": "b371ad0b-09df-49fc-f824-00c42743de3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     predicted  actual  error_squared\n",
            "0    37.626774      42      19.125107\n",
            "1    34.115997      26      65.869412\n",
            "2    31.344362      21     107.005831\n",
            "3    32.149845      38      34.224312\n",
            "4    32.979614      42      81.367359\n",
            "..         ...     ...            ...\n",
            "397  31.389843      26      29.050407\n",
            "398  36.039726      39       8.763221\n",
            "399  31.155888      28       9.959627\n",
            "400  35.607365      32      13.013080\n",
            "401  36.243469      32      18.007031\n",
            "\n",
            "[402 rows x 3 columns]\n",
            "The RMSE on the test values is 10.763669382009649.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}