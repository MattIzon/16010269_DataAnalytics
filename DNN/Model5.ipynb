{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOfhbkrhQBCi8/pGPdZHw8i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MattIzon/16010269_DataAnalytics/blob/main/DNN/Model5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DNN Model 5 No District Separation\n",
        "\n",
        "Various Layer Configurations Attempted including:\n",
        "*   58 -> 58 -> 1\n",
        "*   58 -> 116 -> 1\n",
        "*   58 -> 29 -> 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Predictors Removed:\n",
        "*   date\n",
        "*   gust\n",
        "*   hail\n",
        "*   tornado_funnel_cloud\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_364iE3AwpA-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J9vp7tzGf3eA"
      },
      "outputs": [],
      "source": [
        "# Set-up\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "def normalise(df, column_list):\n",
        "  # Normalises df columns in column_list returning a dictionary of column_name: (min_value, max_value) that can be used to recover the original values\n",
        "  params = dict()\n",
        "\n",
        "  for col in column_list:\n",
        "    min = df[col].min()\n",
        "    max = df[col].max()\n",
        "    params[col] = (min, max)\n",
        "    df[col] = (df[col] - min) / (max - min)\n",
        "\n",
        "  return params\n",
        "\n",
        "\n",
        "def normalise_w_params(df, params, column_list):\n",
        "  # Normalises df columns using the provided params\n",
        "  for col in column_list:\n",
        "    min = params[col][0]\n",
        "    max = params[col][1]\n",
        "    df[col] = (df[col] - min) / (max - min)\n",
        "\n",
        "\n",
        "def denormalise(df, params, column_list):\n",
        "  # Uses the params dictionary produced during normalisation and a list of columns to recover their original values\n",
        "  for col in column_list:\n",
        "    min = params[col][0]\n",
        "    max = params[col][1]\n",
        "    df[col] = (df[col] * (max-min)) + min\n",
        "\n",
        "\n",
        "def flat_list(nested_list):\n",
        "  return [value for sublist in nested_list for value in sublist]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generic = pd.read_csv('https://raw.githubusercontent.com/MattIzon/16010269_DataAnalytics/main/DNN/DNN_day_generic_set.csv')"
      ],
      "metadata": {
        "id": "bs_BolkcBckJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Specific Code goes here"
      ],
      "metadata": {
        "id": "vfxwSyjzIadb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm = ['crime_count', 'temp', 'dewp', 'slp', 'stp', 'visib', 'wdsp', 'mxpsd', 'max', 'min', 'prcp', 'sndp', 'year']\n",
        "data = generic.drop(['date', 'gust', 'hail', 'tornado_funnel_cloud'], axis=1)\n",
        "scale_params = normalise(data, norm)"
      ],
      "metadata": {
        "id": "y4jsaM5JzRIF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.corr()['crime_count']"
      ],
      "metadata": {
        "id": "3XgKIY8acOqe",
        "outputId": "7ad9cd8d-e512-4e16-a23b-11a6ce6e2bb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "crime_count         1.000000\n",
              "temp                0.716466\n",
              "dewp                0.673355\n",
              "slp                -0.273478\n",
              "stp                 0.167965\n",
              "visib               0.218860\n",
              "wdsp               -0.229659\n",
              "mxpsd              -0.146952\n",
              "max                 0.710354\n",
              "min                 0.698121\n",
              "prcp                0.006629\n",
              "sndp               -0.347028\n",
              "fog                -0.092820\n",
              "rain_drizzle        0.006766\n",
              "snow_ice_pellets   -0.375700\n",
              "thunder             0.132278\n",
              "year               -0.048477\n",
              "Fri                 0.170531\n",
              "Mon                 0.009282\n",
              "Sat                 0.031486\n",
              "Sun                -0.062051\n",
              "Thu                -0.034334\n",
              "Tue                -0.071134\n",
              "Wed                -0.044899\n",
              "Apr                -0.093772\n",
              "Aug                 0.277260\n",
              "Dec                -0.164196\n",
              "Feb                -0.298667\n",
              "Jan                -0.222633\n",
              "Jul                 0.269955\n",
              "Jun                 0.242214\n",
              "Mar                -0.201565\n",
              "May                 0.145137\n",
              "Nov                -0.141367\n",
              "Oct                 0.015367\n",
              "Sep                 0.127698\n",
              "Name: crime_count, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seperate train / eval predictors / targets\n",
        "qty_predictors = len(data.columns) - 1\n",
        "qty_targets = 1\n",
        "train_size = int(len(data)*0.8)\n",
        "\n",
        "train_predictors = data.iloc[:train_size,1:]\n",
        "train_targets = data.iloc[:train_size,0]\n",
        "\n",
        "eval_predictors = data.iloc[train_size:,1:]\n",
        "eval_targets = data.iloc[train_size:,0]"
      ],
      "metadata": {
        "id": "Z2KCqEQpiMlT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Design model: layers ~ inputs(58) ->  h1(30) -> h2(15) -> outputs(1)\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Input(shape = (qty_predictors,)))\n",
        "model.add(tf.keras.layers.Dense(29, activation='sigmoid'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.001))"
      ],
      "metadata": {
        "id": "vjj8Be7yqkLH"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVJsFwGFziXv",
        "outputId": "34952d5d-d673-4bf5-8004-85b03709a2d4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 30)                1080      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 15)                465       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 16        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,561\n",
            "Trainable params: 1,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "history = model.fit(train_predictors, train_targets, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2UP_cSK0QnO",
        "outputId": "e8fe1dff-8869-433c-95dc-8f8a7be51b6a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0432\n",
            "Epoch 2/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0282\n",
            "Epoch 3/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0243\n",
            "Epoch 4/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0214\n",
            "Epoch 5/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0194\n",
            "Epoch 6/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0179\n",
            "Epoch 7/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0170\n",
            "Epoch 8/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0163\n",
            "Epoch 9/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0159\n",
            "Epoch 10/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0155\n",
            "Epoch 11/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0153\n",
            "Epoch 12/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0151\n",
            "Epoch 13/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0151\n",
            "Epoch 14/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0149\n",
            "Epoch 15/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0148\n",
            "Epoch 16/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0147\n",
            "Epoch 17/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0147\n",
            "Epoch 18/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0146\n",
            "Epoch 19/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0146\n",
            "Epoch 20/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0146\n",
            "Epoch 21/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0145\n",
            "Epoch 22/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0145\n",
            "Epoch 23/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0145\n",
            "Epoch 24/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0144\n",
            "Epoch 25/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0144\n",
            "Epoch 26/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0143\n",
            "Epoch 27/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0143\n",
            "Epoch 28/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0142\n",
            "Epoch 29/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0143\n",
            "Epoch 30/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0142\n",
            "Epoch 31/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0142\n",
            "Epoch 32/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0142\n",
            "Epoch 33/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0141\n",
            "Epoch 34/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0141\n",
            "Epoch 35/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0141\n",
            "Epoch 36/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0141\n",
            "Epoch 37/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0142\n",
            "Epoch 38/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0140\n",
            "Epoch 39/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0141\n",
            "Epoch 40/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0140\n",
            "Epoch 41/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0140\n",
            "Epoch 42/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0141\n",
            "Epoch 43/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0140\n",
            "Epoch 44/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0139\n",
            "Epoch 45/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0140\n",
            "Epoch 46/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0141\n",
            "Epoch 47/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0140\n",
            "Epoch 48/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0139\n",
            "Epoch 49/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0140\n",
            "Epoch 50/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0139\n",
            "Epoch 51/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0139\n",
            "Epoch 52/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0139\n",
            "Epoch 53/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0139\n",
            "Epoch 54/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0140\n",
            "Epoch 55/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0139\n",
            "Epoch 56/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0139\n",
            "Epoch 57/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0138\n",
            "Epoch 58/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0139\n",
            "Epoch 59/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0138\n",
            "Epoch 60/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0138\n",
            "Epoch 61/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0138\n",
            "Epoch 62/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0138\n",
            "Epoch 63/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0138\n",
            "Epoch 64/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0138\n",
            "Epoch 65/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0138\n",
            "Epoch 66/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0137\n",
            "Epoch 67/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0138\n",
            "Epoch 68/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0138\n",
            "Epoch 69/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0138\n",
            "Epoch 70/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0137\n",
            "Epoch 71/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0138\n",
            "Epoch 72/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0138\n",
            "Epoch 73/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0138\n",
            "Epoch 74/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0137\n",
            "Epoch 75/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0137\n",
            "Epoch 76/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0137\n",
            "Epoch 77/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0137\n",
            "Epoch 78/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0137\n",
            "Epoch 79/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0138\n",
            "Epoch 80/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0137\n",
            "Epoch 81/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0137\n",
            "Epoch 82/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0137\n",
            "Epoch 83/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0138\n",
            "Epoch 84/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0137\n",
            "Epoch 85/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0137\n",
            "Epoch 86/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0137\n",
            "Epoch 87/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0137\n",
            "Epoch 88/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0137\n",
            "Epoch 89/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0136\n",
            "Epoch 90/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0137\n",
            "Epoch 91/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0137\n",
            "Epoch 92/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0137\n",
            "Epoch 93/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0136\n",
            "Epoch 94/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0136\n",
            "Epoch 95/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0136\n",
            "Epoch 96/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0137\n",
            "Epoch 97/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0136\n",
            "Epoch 98/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0136\n",
            "Epoch 99/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0137\n",
            "Epoch 100/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View training history\n",
        "plt.plot(history.history['loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "e9wcugdS2zyM",
        "outputId": "29e01580-d910-4539-9402-e82ee570a9ba"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f10e5303a90>]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAf8klEQVR4nO3dfZBddZ3n8ff3Pt9+7vRDnklHkhGDiANtfFicUlGEGTXODszgUEptMcu4SK3OrLuLtTWUsv7DOiWzlsguCg5SKrgoM3HEwVVwXB0NdHgQEkCaEEg6D93p9PPDffzuH/d056bTTd8k3bnkns+r6lbf8zu/e+7vx0mdD+d3fudcc3dERCR8ItVugIiIVIcCQEQkpBQAIiIhpQAQEQkpBYCISEjFqt2Ak9He3u5dXV3VboaIyFll586dR9y9Y275WRUAXV1d9PT0VLsZIiJnFTN7Zb5yDQGJiISUAkBEJKQUACIiIaUAEBEJKQWAiEhIKQBEREJKASAiElKhCIC//9XL/PDpA9VuhojI60ooAuA7j73Kj357sNrNEBF5XQlFACRjUTL5QrWbISLyuhKSAIiQLRSr3QwRkdeVcARAPEImpwAQESkXjgCIRcnkFQAiIuVCEgARXQMQEZkjFAGQiEV0BiAiMkcoAiAZ0zUAEZG5QhIAmgYqIjJXSAJAQ0AiInOFIwDiEbIKABGR44QjAGJR8kUnr5vBRERmhSQASt3U3cAiIseEKgA0E0hE5JhQBEAiFgXQhWARkTKhCIDZMwBNBRURmRWOAIjPBIDOAEREZoQjAGaGgHQNQERkVkUBYGaXm9kLZtZrZjfNsz5pZvcH63eYWdec9eeY2biZfbbSbS6lY7OANAQkIjJj0QAwsyhwO3AFsAX4mJltmVPtOmDI3TcBtwG3zln/ZeDHJ7nNJaNZQCIiJ6rkDGAr0Ovue9w9C9wHbJtTZxtwT/D+AeBSMzMAM/so8DKw6yS3uWSScc0CEhGZq5IAWAvsK1veH5TNW8fd88AI0GZmDcB/Bb5wCtsEwMyuN7MeM+sZGBiooLknSkQ1C0hEZK7lvgj8eeA2dx8/1Q24+53u3u3u3R0dHae0Dc0CEhE5UayCOn3A+rLldUHZfHX2m1kMaAYGgbcDV5rZ/wBagKKZTQM7K9jmktE1ABGRE1USAI8Dm81sI6WD9NXAn8+psx24Fvg1cCXwiLs78O6ZCmb2eWDc3b8ahMRi21wys9NANQQkIjJr0QBw97yZ3Qg8DESBu919l5ndAvS4+3bgLuBeM+sFjlI6oJ/0Nk+zLwvSEJCIyIkqOQPA3R8CHppTdnPZ+2ngqkW28fnFtrlcjj0KQgEgIjIjFHcCH5sFpAAQEZkRigAws+BnIXUNQERkRigCACARi2gWkIhImdAEQDIW1RCQiEiZEAWAhoBERMqFJwDiEZ0BiIiUCU8AxKK6BiAiUiZEARAhW1AAiIjMCFUAZHK6BiAiMiM8ARDXLCARkXKhCYBEVBeBRUTKhSYASrOANAQkIjIjPAGgO4FFRI4TogDQNQARkXIhCgANAYmIlAtPAMQjZHUGICIyKzwBEAwBlX6pUkREQhQApa7qbmARkZLQBYAuBIuIlIQvADQVVEQECFUARAE0E0hEJBCeAIhrCEhEpFx4AkBDQCIixwlRAJSGgDQLSESkJEQBMHMGoGsAIiJQYQCY2eVm9oKZ9ZrZTfOsT5rZ/cH6HWbWFZRvNbOngtfTZvbHZZ/Za2bPBOt6lqpDC0loGqiIyHFii1UwsyhwO/ABYD/wuJltd/fdZdWuA4bcfZOZXQ3cCvwZ8CzQ7e55M1sNPG1mP3T3fPC597r7kaXs0EKOzQJSAIiIQGVnAFuBXnff4+5Z4D5g25w624B7gvcPAJeambn7ZNnBPgVU7TkMx2YBaQhIRAQqC4C1wL6y5f1B2bx1ggP+CNAGYGZvN7NdwDPAJ8sCwYGfmNlOM7t+oS83s+vNrMfMegYGBirp07w0C0hE5HjLfhHY3Xe4+/nA24DPmVkqWHWJu18EXAF8ysz+YIHP3+nu3e7e3dHRccrt0BCQiMjxKgmAPmB92fK6oGzeOmYWA5qBwfIK7v4cMA68OVjuC/72Aw9SGmpaNseeBaQhIBERqCwAHgc2m9lGM0sAVwPb59TZDlwbvL8SeMTdPfhMDMDMNgDnAXvNrN7MGoPyeuAySheMl83MNQD9JoCISMmis4CCGTw3Ag8DUeBud99lZrcAPe6+HbgLuNfMeoGjlEIC4BLgJjPLAUXgBnc/YmZvAB40s5k2fMfd/3mpO1cuEdU0UBGRcosGAIC7PwQ8NKfs5rL308BV83zuXuDeecr3ABeebGNPRywaIRoxDQGJiARCcycwBL8LrFlAIiJAGANAQ0AiIkDoAiCqISARkUC4AiCuMwARkRnhCgBdAxARmRWyAIjq9wBERAIhC4CIrgGIiARCFQAJDQGJiMwKVQBoGqiIyDEhCwBNAxURmRGuANA0UBGRWeEKAF0DEBGZFbIA0BCQiMiMkAVARL8HICISCFcA6BqAiMisUAVAIholX3TyuhtYRCRcATD7s5AKABGRkAXAzA/DayaQiEjYAiAK6HeBRUQgdAEw88PwmgoqIhKuAIjPBIDOAEREwhUAwRCQ7gUQEQlZACQ0BCQiMitUAaBZQCIix1QUAGZ2uZm9YGa9ZnbTPOuTZnZ/sH6HmXUF5VvN7Kng9bSZ/XGl21wOxy4CKwBERBYNADOLArcDVwBbgI+Z2ZY51a4Dhtx9E3AbcGtQ/izQ7e5vBS4H/reZxSrc5pI7Ng1UQ0AiIpWcAWwFet19j7tngfuAbXPqbAPuCd4/AFxqZubuk+6eD8pTgJ/ENpecZgGJiBxTSQCsBfaVLe8PyuatExzwR4A2ADN7u5ntAp4BPhmsr2SbBJ+/3sx6zKxnYGCgguYuTNcARESOWfaLwO6+w93PB94GfM7MUif5+Tvdvdvduzs6Ok6rLRoCEhE5ppIA6APWly2vC8rmrWNmMaAZGCyv4O7PAePAmyvc5pLTEJCIyDGVBMDjwGYz22hmCeBqYPucOtuBa4P3VwKPuLsHn4kBmNkG4Dxgb4XbXHKJqAJARGRGbLEK7p43sxuBh4EocLe77zKzW4Aed98O3AXca2a9wFFKB3SAS4CbzCwHFIEb3P0IwHzbXOK+nUDTQEVEjlk0AADc/SHgoTllN5e9nwaumudz9wL3VrrN5WZmJGIRXQMQESFkdwJD6SxAs4BEREIZAFENAYmIEMoA0BCQiAiEMQDiEZ0BiIgQxgCIRXUNQESEEAZAIhYhW1AAiIiELgAakzFGpnLVboaISNWFLgBWN6c4ODxV7WaIiFRd6AJgTUuagfGMfhdYREIvdAGwtiWNOxwena52U0REqip0AbCmJQ1An4aBRCTkQhgApZ8jOKAAEJGQC10ArG4unQEoAEQk7EIXAOlElBX1CQ6M6BqAiIRb6AIASsNAOgMQkbALZwA0pxUAIhJ64QyAljR9Q1O4e7WbIiJSNaEMgLUtaSayBUan89VuiohI1YQyAGbuBTg4omEgEQmvUAbAat0LICISzgBYO3s3sKaCikh4hTIAOhqSxKOmMwARCbVQBkAkYqxq1r0AIhJuoQwAKN0LcFBDQCISYqENgLUtaT0RVERCraIAMLPLzewFM+s1s5vmWZ80s/uD9TvMrCso/4CZ7TSzZ4K/7yv7zM+DbT4VvDqXqlOVWN2S4tDoNIWibgYTkXBaNADMLArcDlwBbAE+ZmZb5lS7Dhhy903AbcCtQfkR4MPufgFwLXDvnM9d4+5vDV79p9GPk7amJU2h6PSPaRhIRMKpkjOArUCvu+9x9yxwH7BtTp1twD3B+weAS83M3P1Jdz8QlO8C0maWXIqGn66Zm8F0IVhEwqqSAFgL7Ctb3h+UzVvH3fPACNA2p86fAE+4e6as7JvB8M/fmJnN9+Vmdr2Z9ZhZz8DAQAXNrcza2QDQGYCIhNMZuQhsZudTGhb6y7Lia4KhoXcHr4/P91l3v9Pdu929u6OjY8natLpZdwOLSLhVEgB9wPqy5XVB2bx1zCwGNAODwfI64EHgE+7+0swH3L0v+DsGfIfSUNMZ05iK05SKKQBEJLQqCYDHgc1mttHMEsDVwPY5dbZTusgLcCXwiLu7mbUAPwJucvdfzVQ2s5iZtQfv48CHgGdPrysnb01LWo+DEJHQWjQAgjH9G4GHgeeA77n7LjO7xcw+ElS7C2gzs17gr4GZqaI3ApuAm+dM90wCD5vZb4GnKJ1BfH0pO1aJtS1p9g9NnumvFRF5XYhVUsndHwIemlN2c9n7aeCqeT73ReCLC2z24sqbuTw2ttfzq5eOUCw6kci816BFRGpWaO8EBtjU2cB0rqg7gkUklEIfAAAv9o9VuSUiImeeAgDo7R+vcktERM68UAdAS12C9oakAkBEQinUAQCwqbNeASAioaQA6Gzgxf5x3PVUUBEJFwVARwNj03kGxjKLVxYRqSGhD4DNKxsBXQgWkfAJfQDMzgQaUACISLiEPgA6G5M0JmM6AxCR0Al9AJgZ53Y28OJhBYCIhEvoAwBKw0AaAhKRsFEAAJs7GxgYyzAylat2U0REzhgFAHokhIiEkwKA8gDQQ+FEJDwUAMC61joSsYjOAEQkVBQAQDRivKFdzwQSkXBRAAQ2r2zkd5oKKiIhogAIvGVtM33DU/SP6UfiRSQcFACBi7taAXjilaEqt0RE5MxQAATOX9NEIhZhpwJAREJCARBIxqK8ZW0zPQoAEQkJBUCZi7taebZvhOlcodpNERFZdgqAMhef00qu4DzbN1LtpoiILLuKAsDMLjezF8ys18xummd90szuD9bvMLOuoPwDZrbTzJ4J/r6v7DMXB+W9ZvYVM7Ol6tSpumhD6UKwhoFEJAwWDQAziwK3A1cAW4CPmdmWOdWuA4bcfRNwG3BrUH4E+LC7XwBcC9xb9pk7gH8PbA5el59GP5ZEe0OSje31uhAsIqFQyRnAVqDX3fe4exa4D9g2p8424J7g/QPApWZm7v6kux8IyncB6eBsYTXQ5O6/8dKvsX8L+Ohp92YJXHROK0+8MqQfiReRmldJAKwF9pUt7w/K5q3j7nlgBGibU+dPgCfcPRPU37/INgEws+vNrMfMegYGBipo7um5eEMrgxNZ9g5OLvt3iYhU0xm5CGxm51MaFvrLk/2su9/p7t3u3t3R0bH0jZujO7ghTMNAIlLrKgmAPmB92fK6oGzeOmYWA5qBwWB5HfAg8Al3f6ms/rpFtlkVmzoaaErF2PnK0Wo3RURkWVUSAI8Dm81so5klgKuB7XPqbKd0kRfgSuARd3czawF+BNzk7r+aqezuB4FRM3tHMPvnE8A/nmZflkQkYly0oZWevToDEJHatmgABGP6NwIPA88B33P3XWZ2i5l9JKh2F9BmZr3AXwMzU0VvBDYBN5vZU8GrM1h3A/ANoBd4CfjxUnXqdG3duIIX+8c5NKIHw4lI7bKzabZLd3e39/T0LPv39PaP8f4v/4L/vu18Pv7OrmX/PhGR5WRmO929e2657gSex6bORt7QUc/Duw5XuykiIstGAbCAy7as4jd7BhmZzFW7KSIiy0IBsIAPnr+SfNH52fM6CxCR2qQAWMCF61pY2ZTkJxoGEpEapQBYQCRiXLZlFf/yuwE9HlpEapIC4DVcdv5KpnIFfvG75X8EhYjImaYAeA3veEMbTakYP9mtYSARqT0KgNcQj0a49E0r+elzh8nkNQwkIrVFAbCIf3vRWoYnczz4xOviUUUiIktGAbCISza1c8HaZu74l5fIF4rVbo6IyJJRACzCzPjUezfxyuAkP3rmYLWbIyKyZBQAFbhsy0o2dzbwtUdfolg8e56dJCLyWhQAFYhEjBveey4vHB7jp89pRpCI1AYFQIU+/JY1rF+R5vZHe/V7wSJSExQAFYpFI9zwnk08vX+EB5/UjCAROfspAE7Cn3avp3tDK5/fvovDo/qxGBE5uykATkI0YnzpqgvJFop87gfPaChIRM5qCoCTtLG9nv/8wfN45Pl+vq+bw0TkLKYAOAX/7l1dbO1awRd+uIsXDo1VuzkiIqdEAXAKIhHjb6+6kLpElCv/17+yY89gtZskInLSFACn6Jy2Or7/H95FZ2OSj9/9GD/WXcIicpZRAJyGda11PPDJd3HB2mZu+M4TfOnh58npeUEicpZQAJym1voE3/6Lt3PlReu4/dGXuPKOf2XPwHi1myUisigFwBJIxaN86aoLueOai9g7OMkffeWXfOnh5xkcz1S7aSIiC6ooAMzscjN7wcx6zeymedYnzez+YP0OM+sKytvM7FEzGzezr875zM+DbT4VvDqXokPVdMUFq3n4M3/A+87r5Gs/f4lLbn2UW364mwPDU9VumojICWKLVTCzKHA78AFgP/C4mW13991l1a4Dhtx9k5ldDdwK/BkwDfwN8ObgNdc17t5zmn14XVnVnOL2ay6it3+Mr/38Je759V6+9eu9fPjCNfzFuzdy/prmajdRRASoIACArUCvu+8BMLP7gG1AeQBsAz4fvH8A+KqZmbtPAL80s01L1+Szw6bORr78p2/lr97/e3zzV3u57/FXefDJPuoSUVrrEqyoT/DOc9v4+Ds2sH5FXbWbKyIhVEkArAX2lS3vB96+UB13z5vZCNAGHFlk2980swLwfeCLXoPPVli/oo6bP7yFT79/M//wZB+vHp1kaDLL4dFp7vrly3z9/+3h0vNW8oEtnZyzop4NbXWsakoRiVi1my4iNa6SAFgu17h7n5k1UgqAjwPfmlvJzK4Hrgc455xzzmwLl1BzOs617+o6ruzgyBTf/s2rfPexV4/7nYH6RJQ3rW5iy5omNq9s5JwVdaxvTbOmJU0qHj3DLReRWlVJAPQB68uW1wVl89XZb2YxoBl4zdtj3b0v+DtmZt+hNNR0QgC4+53AnQDd3d01dYawujnNZz/4Rj7z/s0cGJ7m1aOTvHJ0ghcPj7PrwAg/eKKP8Uz+uM80JGOsqE+wqjnFltVNbFndxJqWNIMTGfpHM0znCrxpdRNvWd9MZ2OqSj0TkbNBJQHwOLDZzDZSOtBfDfz5nDrbgWuBXwNXAo+81nBOEBIt7n7EzOLAh4CfnkL7a0IsGuGctjrOaavjEtpny4tFZ2A8w6tHJ3l1cJJDo9MMjmc5OlEq+17PPiazhQW329GYZFVTiraGBK11CXKFItO5IoVikQ1t9Zy3qpFNnQ1M5Qr0j2Y4OpFlQ1sdb+taQWt94kx0XUSqaNEACMb0bwQeBqLA3e6+y8xuAXrcfTtwF3CvmfUCRymFBABmthdoAhJm9lHgMuAV4OHg4B+ldPD/+pL2rAZEIsbKphQrm1K8rWvFCeuLRWfv4ASHRzN0NCboaEwRjxq7D4zy9P4Rnj84ysB4hiPjGXr7x0lEIyRiESJm7Hj56GuGx+bOBs7taKC9MUFHQ4q1rWk2ttexsb0Bd+fA8DR9w1MU3WmrT9DemKSzMUljKr6c/0lEZAnZ2XTdtbu723t6amrWaNUUi86+oUn2DExQl4jS2ZRiRV2C3/WP8djLR+nZe5S+4SkGxjIMTeYq3m5TKsaaljQtdXGmc0WmcwUiZqxqTrGqOUVbfQIDil4KuKZUjJa6BA3JWHCGUmA6X2Qqm2cqWyRbKHDeqia2blzByqbSkFY2X2RgPEN7Q4JkbOmuieQKRcan8zr7kZpjZjvdvXtueTUvAksVRSLGhrZ6NrTVH1f+tq4VJ5xtZPNF+oanePnIOHsGJoiYsbY1zdqWNNGIMTie5ch4hsOjpbOCvqEpxqbzNKZidDQmKRadQ6PTPL1vmMGJLGbMhsBiohGjEFRc15omVyjSP5bBHZKxCBdvaGXrxhVEzdg3NMmrRycZnswxnskzmS3QUhfnwnUtvGVdM+d2NNCUjtOUilF0ODw6zaGRaV4aGKfnlSF+u3+Y6VyRczvquWRTO+88t52LNrTMXktxdw6MTPPi4TGa03E6m1J0NCRJxCq7of7IeIYnXhliOl+kOR2nOR2nozHJysYksahuypczT2cAUjXFojOWyTMymWN0OkcyFiEVj5KMR6hLxEjHo7g7uw+O8tjLR3ly3zD1iShrWtJ0Nqbo7R/nN3sGee7QKO6lax7rW9O0NyRpSMZIJ6L0j2V4et8w/WMLP5YjFjHOX9PERRtaaW9I8tjLR3ns5aNM5UpDZGtb0mxsr+f5Q2McmefxHvWJKE3BAb05Hae1LkFzujQUlg3Oap47OMrewcl5vz8aMVY1pVjXWvqeje311CVjHBnLMDCeYSpboC4RpSEZoykdZ11rmnWtaZrTCfpHpzk4Ms3wVI62+gSdjUlWNCSImFF0p1B0JjIFxjM5JjIF4tEIdYko9ckoK5tSrG4uhThAJl+YnUjggDvUJaKsqE9Ql4hiNv/UZHfHHZxSsGsK8+vPQmcACgA5641O54hHIqQTCw8HHRqZZt/QJKNTOcam8zjOyqYUq5pS806vzeaLPNM3zJOvDvPkvmFeGZzg91Y28tb1LbxxZSMT2TyHRzMMjGUYmcod9xqezDI8mcMMErEI8WiEczsa6N7QSndXK02p+Gzd/rEMfUNT9A1P8erRSfYemWBwIjvbjrb6BOlElKlsgYlsnunc0j5tNhYxVrekmMoW5w23GYlYhI6GJCubkqxqTuEO+4Ym2T80xfCcIUIziEciJOMROoJrQy3pxGwYZvJFCkUvBQelAIxHIsSiRnnGZHJFJrMFpnMFErEIjakYjak4qXiERLT037UhFaMlnaClLs7geIZdB0bZfXCUbL7IhrY6utrrWdOcpiEVozEVoy4RJRGNEo8a8Vhk9nuLRefIRJaBsQwTmfxsGHc0JtkzMMHug6PsGRgnGYvSlI7RlIpTn4xRn4xSnyjNzGtvSNLemCQVixCNGGals9fJbJ6pbIGjk1n6g38z6USULaubOGdF3XGBmc0XGZ7MMjSZI1co0tmYpK0hORvSp0oBIHKWGJnMMZUr0NaQID5naGgym+fA8BT7jk4xMpWjsynJ6uY0Len47AHmaBAgEQMzoyEZoyE4+GXzRaZyBcYzeQ6NlKYe9w1NUZ+MsqopzarmJHWJ2OyBeDJTOnAdnchyZCzDodFpDo1OA7C+tY71K9KsqE+WvgvDKZ115IvOZCbPwHhpevLIVI5kPEIqVjrDi0YizBzTCkUnVyiSL5SORTNHpGSsdLaSjJfaPT6dZzyTZzpXIFsokskVGc/kZ6dKRwzO7Wjg/DVNpOJR9g5OsPfIJP1j0xUNNy6mvSFJoVhkdDo/Oyz5WiK2+DBnfSJKe2OSicxM304M+IiVvvuRz76HhuSpjdrrGoDIWaK5Lk4z88+mqkvE2NTZyKbOxhPWtdYnOLejYbmb97qTKxQZmcpRn4jNexbo7qXQm84zkS2QKxTJ5otkg9DJF4pg0NGQpKMxSToRZf/QFC8PTHB4bJqN7fVsWd1ES11idnuT2QITmdL2xqfzDE5kODKeZXA8QyZfJF90CsUi8Whktl0tdXE6G1N0NiYZm86z++AIuw+MMjyVoz4ZoyEZozEZo6U+wYq6BNGIBQE6zZHxDPWvcYZ7qhQAInJWi0cjtDckF1xvZtQlYtQlKj/cndvRsGCYmlkw/HN6h88L1lX/wZCaeiAiElIKABGRkFIAiIiElAJARCSkFAAiIiGlABARCSkFgIhISCkARERC6qx6FISZDVD6LYFT0c7iv1Fca8LYZwhnv8PYZwhnv0+lzxvcvWNu4VkVAKfDzHrmexZGLQtjnyGc/Q5jnyGc/V7KPmsISEQkpBQAIiIhFaYAuLPaDaiCMPYZwtnvMPYZwtnvJetzaK4BiIjI8cJ0BiAiImUUACIiIVXzAWBml5vZC2bWa2Y3Vbs9y8XM1pvZo2a228x2mdmng/IVZvZ/zezF4G9rtdu61MwsamZPmtk/BcsbzWxHsM/vN7NEtdu41MysxcweMLPnzew5M3tnre9rM/ur4N/2s2b2XTNL1eK+NrO7zazfzJ4tK5t331rJV4L+/9bMLjqZ76rpADCzKHA7cAWwBfiYmW2pbquWTR74T+6+BXgH8KmgrzcBP3P3zcDPguVa82ngubLlW4Hb3H0TMARcV5VWLa//Cfyzu58HXEip/zW7r81sLfAfgW53fzMQBa6mNvf13wOXzylbaN9eAWwOXtcDd5zMF9V0AABbgV533+PuWeA+YFuV27Qs3P2guz8RvB+jdEBYS6m/9wTV7gE+Wp0WLg8zWwf8EfCNYNmA9wEPBFVqsc/NwB8AdwG4e9bdh6nxfU3pJ2zTZhYD6oCD1OC+dvdfAEfnFC+0b7cB3/KS3wAtZra60u+q9QBYC+wrW94flNU0M+sCfh/YAax094PBqkPAyio1a7n8HfBfgGKw3AYMu3s+WK7Ffb4RGAC+GQx9fcPM6qnhfe3ufcDfAq9SOvCPADup/X09Y6F9e1rHuFoPgNAxswbg+8Bn3H20fJ2X5vzWzLxfM/sQ0O/uO6vdljMsBlwE3OHuvw9MMGe4pwb3dSul/9vdCKwB6jlxmCQUlnLf1noA9AHry5bXBWU1yczilA7+33b3HwTFh2dOCYO//dVq3zL4N8BHzGwvpeG991EaG28JhgmgNvf5fmC/u+8Ilh+gFAi1vK/fD7zs7gPungN+QGn/1/q+nrHQvj2tY1ytB8DjwOZgpkCC0kWj7VVu07IIxr7vAp5z9y+XrdoOXBu8vxb4xzPdtuXi7p9z93Xu3kVp3z7i7tcAjwJXBtVqqs8A7n4I2GdmbwyKLgV2U8P7mtLQzzvMrC74tz7T55re12UW2rfbgU8Es4HeAYyUDRUtzt1r+gX8IfA74CXgv1W7PcvYz0sonRb+FngqeP0hpTHxnwEvAj8FVlS7rcvU//cA/xS8fwPwGNAL/B8gWe32LUN/3wr0BPv7H4DWWt/XwBeA54FngXuBZC3ua+C7lK5z5Cid7V230L4FjNJMx5eAZyjNkqr4u/QoCBGRkKr1ISAREVmAAkBEJKQUACIiIaUAEBEJKQWAiEhIKQBEREJKASAiElL/H/+2hGBLwxxkAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test model\n",
        "eval_predictions = flat_list(model.predict(eval_predictors))"
      ],
      "metadata": {
        "id": "F3hcZ9wt31pC"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse model quality vs mean \n",
        "rmse = np.sqrt(np.mean((eval_targets.values - eval_predictions)**2))\n",
        "print('LinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "avg = np.mean(train_targets)\n",
        "\n",
        "rmse = np.sqrt(np.mean((eval_targets.values - avg)**2))\n",
        "print('Using the training data mean of {0} would have has resulted in a RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iYPVeVC7KYR",
        "outputId": "3a7afb23-f4f4-4bcc-fd90-10d054cbfb6a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression has RMSE of 0.12035461594209336\n",
            "Using the training data mean of 0.5124725877192983 would have has resulted in a RMSE of 0.18958985670076428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "\n",
        "test = pd.read_csv('https://raw.githubusercontent.com/MattIzon/16010269_DataAnalytics/main/DNN/DNN_day_test_set.csv')\n",
        "test.drop(['date', 'gust', 'hail', 'tornado_funnel_cloud'], axis=1, inplace=True)\n",
        "test_predictors = test.iloc[:,1:]\n",
        "normalise_w_params(test_predictors, scale_params, norm[1:])\n",
        "\n",
        "test_predictions = pd.DataFrame(flat_list(model.predict(test_predictors)), columns=['crime_count'])\n",
        "denormalise(test_predictions, scale_params, ['crime_count'])\n",
        "test_targets = test['crime_count']\n",
        "\n",
        "results = pd.DataFrame()\n",
        "results['predicted'] = test_predictions\n",
        "results['actual'] = test_targets\n",
        "results['error_squared'] = (results['predicted'] - results['actual']) ** 2\n",
        "print(results)\n",
        "\n",
        "print('The RMSE on the test values is {}.'.format(np.sqrt(np.mean(results.error_squared))))\n",
        "print()"
      ],
      "metadata": {
        "id": "jsSl4tvr2aNX",
        "outputId": "fb42689a-1109-421f-9c3b-08a92b7ccac4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     predicted  actual  error_squared\n",
            "0   655.180847     631     584.713370\n",
            "1   677.989197     686      64.172968\n",
            "2   832.458252     859     704.464389\n",
            "3   677.837585     720    1777.669201\n",
            "4   739.907410     745      25.934476\n",
            "5   754.824524     791    1308.665069\n",
            "6   776.118408     702    5493.538435\n",
            "7   688.796143     726    1384.127007\n",
            "8   713.410522     741     761.179271\n",
            "9   621.445312     572    2444.838928\n",
            "10  734.251221     720     203.097292\n",
            "11  809.673889     826     266.541895\n",
            "12  630.637207     640      87.661892\n",
            "13  702.398682     713     112.387951\n",
            "14  685.511475     717     991.527231\n",
            "15  761.779175     751     116.190609\n",
            "16  761.014038     707    2917.516310\n",
            "The RMSE on the test values is 33.64540550340009.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}