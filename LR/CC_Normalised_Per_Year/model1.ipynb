{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP6cjk1aDllvwnAz9gWYzV8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MattIzon/16010269_DataAnalytics/blob/main/LR/model1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression Model 1\n",
        "Predictors: day_of_week (mon 1 - sun 7)"
      ],
      "metadata": {
        "id": "_364iE3AwpA-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "J9vp7tzGf3eA"
      },
      "outputs": [],
      "source": [
        "# Set-up\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "def flat_list(nested_list):\n",
        "  return [value for sublist in nested_list for value in sublist]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/MattIzon/16010269_DataAnalytics/main/LR/LR1.csv')"
      ],
      "metadata": {
        "id": "FgJ4u-ehgEQX"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "randomised = data.iloc[np.random.permutation(len(data))]"
      ],
      "metadata": {
        "id": "8TXqCBaEgZCw"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictors = randomised.iloc[:,0]\n",
        "targets = randomised.iloc[:,1]\n",
        "train_size = int(len(randomised)*0.8)\n",
        "qty_predictors = 1\n",
        "qty_targets = 1"
      ],
      "metadata": {
        "id": "Z2KCqEQpiMlT"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Design model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(qty_targets, input_shape=[qty_predictors]))\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.01))\n"
      ],
      "metadata": {
        "id": "vjj8Be7yqkLH"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVJsFwGFziXv",
        "outputId": "ab451333-2c99-49ad-dc5a-7ac9edf196f1"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "history = model.fit(predictors.iloc[0:train_size], targets.iloc[0:train_size], epochs=250)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2UP_cSK0QnO",
        "outputId": "518a566a-64a8-4c74-8faf-7f2079bc5074"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "44/44 [==============================] - 1s 2ms/step - loss: 18.8445\n",
            "Epoch 2/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 5.7813\n",
            "Epoch 3/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 1.5098\n",
            "Epoch 4/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.5629\n",
            "Epoch 5/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.4187\n",
            "Epoch 6/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3844\n",
            "Epoch 7/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.3565\n",
            "Epoch 8/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3293\n",
            "Epoch 9/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3027\n",
            "Epoch 10/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.2764\n",
            "Epoch 11/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.2516\n",
            "Epoch 12/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.2280\n",
            "Epoch 13/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.2060\n",
            "Epoch 14/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1854\n",
            "Epoch 15/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.1668\n",
            "Epoch 16/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.1499\n",
            "Epoch 17/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.1347\n",
            "Epoch 18/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1213\n",
            "Epoch 19/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1093\n",
            "Epoch 20/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0986\n",
            "Epoch 21/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0896\n",
            "Epoch 22/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0816\n",
            "Epoch 23/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0746\n",
            "Epoch 24/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0689\n",
            "Epoch 25/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0640\n",
            "Epoch 26/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0599\n",
            "Epoch 27/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0565\n",
            "Epoch 28/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0539\n",
            "Epoch 29/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0515\n",
            "Epoch 30/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0496\n",
            "Epoch 31/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0482\n",
            "Epoch 32/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0469\n",
            "Epoch 33/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0459\n",
            "Epoch 34/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0453\n",
            "Epoch 35/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0448\n",
            "Epoch 36/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0443\n",
            "Epoch 37/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0440\n",
            "Epoch 38/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 39/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0435\n",
            "Epoch 40/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0435\n",
            "Epoch 41/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0433\n",
            "Epoch 42/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 43/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 44/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 45/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 46/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 47/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0430\n",
            "Epoch 48/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 49/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 50/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0432\n",
            "Epoch 51/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 52/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 53/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 54/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0430\n",
            "Epoch 55/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0430\n",
            "Epoch 56/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0430\n",
            "Epoch 57/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0433\n",
            "Epoch 58/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0436\n",
            "Epoch 59/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 60/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 61/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 62/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 63/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 64/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 65/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0432\n",
            "Epoch 66/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0433\n",
            "Epoch 67/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0430\n",
            "Epoch 68/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 69/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 70/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 71/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 72/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0432\n",
            "Epoch 73/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 74/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 75/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 76/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 77/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0432\n",
            "Epoch 78/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 79/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0432\n",
            "Epoch 80/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 81/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 82/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 83/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0430\n",
            "Epoch 84/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0435\n",
            "Epoch 85/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0432\n",
            "Epoch 86/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0436\n",
            "Epoch 87/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 88/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0432\n",
            "Epoch 89/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0435\n",
            "Epoch 90/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0436\n",
            "Epoch 91/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0440\n",
            "Epoch 92/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 93/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 94/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0432\n",
            "Epoch 95/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0430\n",
            "Epoch 96/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 97/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0435\n",
            "Epoch 98/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0432\n",
            "Epoch 99/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0445\n",
            "Epoch 100/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0437\n",
            "Epoch 101/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0432\n",
            "Epoch 102/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 103/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 104/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0439\n",
            "Epoch 105/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0435\n",
            "Epoch 106/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0435\n",
            "Epoch 107/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0432\n",
            "Epoch 108/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 109/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0434\n",
            "Epoch 110/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 111/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0433\n",
            "Epoch 112/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0435\n",
            "Epoch 113/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0436\n",
            "Epoch 114/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0433\n",
            "Epoch 115/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0432\n",
            "Epoch 116/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 117/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0434\n",
            "Epoch 118/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0433\n",
            "Epoch 119/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0434\n",
            "Epoch 120/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0431\n",
            "Epoch 121/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 122/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 123/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0431\n",
            "Epoch 124/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0433\n",
            "Epoch 125/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 126/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0434\n",
            "Epoch 127/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0436\n",
            "Epoch 128/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0435\n",
            "Epoch 129/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0434\n",
            "Epoch 130/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 131/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0434\n",
            "Epoch 132/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0434\n",
            "Epoch 133/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0434\n",
            "Epoch 134/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0433\n",
            "Epoch 135/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0435\n",
            "Epoch 136/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0433\n",
            "Epoch 137/250\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0439\n",
            "Epoch 138/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0440\n",
            "Epoch 139/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0433\n",
            "Epoch 140/250\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0434\n",
            "Epoch 141/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0441\n",
            "Epoch 142/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0447\n",
            "Epoch 143/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 144/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 145/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0437\n",
            "Epoch 146/250\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0433\n",
            "Epoch 147/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0434\n",
            "Epoch 148/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0433\n",
            "Epoch 149/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0448\n",
            "Epoch 150/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0437\n",
            "Epoch 151/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0442\n",
            "Epoch 152/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0443\n",
            "Epoch 153/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0437\n",
            "Epoch 154/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0441\n",
            "Epoch 155/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0432\n",
            "Epoch 156/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0439\n",
            "Epoch 157/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0434\n",
            "Epoch 158/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0433\n",
            "Epoch 159/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0434\n",
            "Epoch 160/250\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.0433\n",
            "Epoch 161/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0432\n",
            "Epoch 162/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0440\n",
            "Epoch 163/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0434\n",
            "Epoch 164/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0433\n",
            "Epoch 165/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0446\n",
            "Epoch 166/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0454\n",
            "Epoch 167/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0433\n",
            "Epoch 168/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0435\n",
            "Epoch 169/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 170/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0433\n",
            "Epoch 171/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0435\n",
            "Epoch 172/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0432\n",
            "Epoch 173/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0433\n",
            "Epoch 174/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0432\n",
            "Epoch 175/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0439\n",
            "Epoch 176/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0437\n",
            "Epoch 177/250\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0437\n",
            "Epoch 178/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0433\n",
            "Epoch 179/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0447\n",
            "Epoch 180/250\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0444\n",
            "Epoch 181/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0437\n",
            "Epoch 182/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 183/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0437\n",
            "Epoch 184/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0440\n",
            "Epoch 185/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0442\n",
            "Epoch 186/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0434\n",
            "Epoch 187/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0434\n",
            "Epoch 188/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0437\n",
            "Epoch 189/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0437\n",
            "Epoch 190/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0441\n",
            "Epoch 191/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0446\n",
            "Epoch 192/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0434\n",
            "Epoch 193/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 194/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0452\n",
            "Epoch 195/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0438\n",
            "Epoch 196/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0436\n",
            "Epoch 197/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 198/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0449\n",
            "Epoch 199/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0434\n",
            "Epoch 200/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0444\n",
            "Epoch 201/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0434\n",
            "Epoch 202/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0444\n",
            "Epoch 203/250\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0437\n",
            "Epoch 204/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0438\n",
            "Epoch 205/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 206/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0438\n",
            "Epoch 207/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0437\n",
            "Epoch 208/250\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0441\n",
            "Epoch 209/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 210/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0452\n",
            "Epoch 211/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 212/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0434\n",
            "Epoch 213/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0440\n",
            "Epoch 214/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 215/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0442\n",
            "Epoch 216/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0438\n",
            "Epoch 217/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0433\n",
            "Epoch 218/250\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.0437\n",
            "Epoch 219/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0438\n",
            "Epoch 220/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0451\n",
            "Epoch 221/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0435\n",
            "Epoch 222/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0434\n",
            "Epoch 223/250\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.0437\n",
            "Epoch 224/250\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0440\n",
            "Epoch 225/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0441\n",
            "Epoch 226/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0449\n",
            "Epoch 227/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0452\n",
            "Epoch 228/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0441\n",
            "Epoch 229/250\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0434\n",
            "Epoch 230/250\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.0436\n",
            "Epoch 231/250\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.0441\n",
            "Epoch 232/250\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0433\n",
            "Epoch 233/250\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0437\n",
            "Epoch 234/250\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.0436\n",
            "Epoch 235/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0437\n",
            "Epoch 236/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0434\n",
            "Epoch 237/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0440\n",
            "Epoch 238/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0433\n",
            "Epoch 239/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 240/250\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.0440\n",
            "Epoch 241/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0443\n",
            "Epoch 242/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0434\n",
            "Epoch 243/250\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0436\n",
            "Epoch 244/250\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0436\n",
            "Epoch 245/250\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0444\n",
            "Epoch 246/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0442\n",
            "Epoch 247/250\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.0438\n",
            "Epoch 248/250\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.0442\n",
            "Epoch 249/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0444\n",
            "Epoch 250/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View training history\n",
        "plt.plot(history.history['loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "e9wcugdS2zyM",
        "outputId": "8521aa2c-b258-4263-ea35-69a5f9ff3f77"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f240d716610>]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test model\n",
        "model_test = flat_list(model.predict(predictors.iloc[train_size:]))"
      ],
      "metadata": {
        "id": "F3hcZ9wt31pC"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse model quality vs mean \n",
        "rmse = np.sqrt(np.mean((targets[train_size:].values - model_test)**2))\n",
        "print('LinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "avg = np.mean(data['crime_count'][:train_size])\n",
        "\n",
        "rmse = np.sqrt(np.mean((targets[train_size:].values - avg)**2))\n",
        "print('Using the training data mean of {0} would have has resulted in a RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iYPVeVC7KYR",
        "outputId": "1a41a1b2-ba14-4e2f-b25f-9fce399e8e3a"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression has RMSE of 0.20971105072947288\n",
            "Using the training data mean of 0.5080399258596116 would have has resulted in a RMSE of 0.20895423130412796\n"
          ]
        }
      ]
    }
  ]
}