{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMSen6STZvlaN9g5OLIIvdS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MattIzon/16010269_DataAnalytics/blob/main/LR/Normalised/dow_temp_snow_ice_pellets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression Model\n",
        "Predictors:\n",
        "*   day_of_week\n",
        "*   temp\n",
        "*   snow_ice_pellets\n",
        "\n"
      ],
      "metadata": {
        "id": "_364iE3AwpA-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "J9vp7tzGf3eA"
      },
      "outputs": [],
      "source": [
        "# Set-up\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "def normalise(df, column_list):\n",
        "  # Normalises df columns in column_list returning a dictionary of column_name: (min_value, max_value) that can be used to recover the original values\n",
        "  params = dict()\n",
        "\n",
        "  for col in column_list:\n",
        "    min = df[col].min()\n",
        "    max = df[col].max()\n",
        "    params[col] = (min, max)\n",
        "    df[col] = (df[col] - min) / (max - min)\n",
        "\n",
        "  return params\n",
        "\n",
        "\n",
        "def normalise_w_params(df, params, column_list):\n",
        "  # Normalises df columns using the provided params\n",
        "  for col in column_list:\n",
        "    min = params[col][0]\n",
        "    max = params[col][1]\n",
        "    df[col] = (df[col] - min) / (max - min)\n",
        "\n",
        "\n",
        "def denormalise(df, params, column_list):\n",
        "  # Uses the params dictionary produced during normalisation and a list of columns to recover their original values\n",
        "  for col in column_list:\n",
        "    min = params[col][0]\n",
        "    max = params[col][1]\n",
        "    df[col] = (df[col] * (max-min)) + min\n",
        "\n",
        "\n",
        "def flat_list(nested_list):\n",
        "  return [value for sublist in nested_list for value in sublist]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generic = pd.read_csv('https://raw.githubusercontent.com/MattIzon/16010269_DataAnalytics/main/LR/Normalised/generic_set.csv')"
      ],
      "metadata": {
        "id": "bs_BolkcBckJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Specific Code goes here"
      ],
      "metadata": {
        "id": "vfxwSyjzIadb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generic.corr()['crime_count']"
      ],
      "metadata": {
        "id": "k9z9nohDSPep",
        "outputId": "4ddd1b4d-68f0-4891-f7d0-3c59ba6645c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "index                   0.197341\n",
              "day_of_week             0.038719\n",
              "crime_count             1.000000\n",
              "mo                      0.199961\n",
              "temp                    0.715968\n",
              "dewp                    0.673428\n",
              "slp                    -0.272455\n",
              "stp                     0.161359\n",
              "visib                   0.216665\n",
              "wdsp                   -0.226882\n",
              "mxpsd                  -0.145715\n",
              "gust                   -0.148226\n",
              "max                     0.709525\n",
              "min                     0.697839\n",
              "prcp                    0.003773\n",
              "sndp                   -0.346634\n",
              "fog                    -0.092184\n",
              "rain_drizzle            0.005482\n",
              "snow_ice_pellets       -0.378491\n",
              "hail                         NaN\n",
              "thunder                 0.132925\n",
              "tornado_funnel_cloud         NaN\n",
              "Name: crime_count, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['day_of_week', 'temp', 'snow_ice_pellets', 'crime_count']\n",
        "data = generic[columns]\n",
        "scale_params = normalise(data, columns)"
      ],
      "metadata": {
        "id": "y4jsaM5JzRIF",
        "outputId": "52d5d412-d58f-4703-fc47-2d8aa1ae3768",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seperate train / eval predictors / targets\n",
        "qty_predictors = 3\n",
        "qty_targets = 1\n",
        "train_size = int(len(data)*0.8)\n",
        "\n",
        "train_predictors = data.iloc[:train_size,0:qty_predictors]\n",
        "train_targets = data.iloc[:train_size,qty_predictors]\n",
        "\n",
        "eval_predictors = data.iloc[train_size:,0:qty_predictors]\n",
        "eval_targets = data.iloc[train_size:,qty_predictors]"
      ],
      "metadata": {
        "id": "Z2KCqEQpiMlT"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Design model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(qty_targets, input_shape=[qty_predictors]))\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.01))"
      ],
      "metadata": {
        "id": "vjj8Be7yqkLH"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVJsFwGFziXv",
        "outputId": "02d53d95-f130-473b-e287-faf09fe1fecf"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 4\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "history = model.fit(train_predictors, train_targets, epochs=250)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2UP_cSK0QnO",
        "outputId": "2b033dcb-2ad2-4b2c-8628-e9b2661e63e6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.2903\n",
            "Epoch 2/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0401\n",
            "Epoch 3/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0313\n",
            "Epoch 4/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0282\n",
            "Epoch 5/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0259\n",
            "Epoch 6/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0245\n",
            "Epoch 7/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0232\n",
            "Epoch 8/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0222\n",
            "Epoch 9/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0216\n",
            "Epoch 10/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0209\n",
            "Epoch 11/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0204\n",
            "Epoch 12/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0198\n",
            "Epoch 13/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0195\n",
            "Epoch 14/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0190\n",
            "Epoch 15/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0186\n",
            "Epoch 16/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0185\n",
            "Epoch 17/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0185\n",
            "Epoch 18/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0182\n",
            "Epoch 19/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0180\n",
            "Epoch 20/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0179\n",
            "Epoch 21/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 22/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 23/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 24/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 25/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0180\n",
            "Epoch 26/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 27/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 28/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "Epoch 29/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 30/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "Epoch 31/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 32/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 33/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 34/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 35/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 36/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 37/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 38/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 39/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 40/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0175\n",
            "Epoch 41/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0179\n",
            "Epoch 42/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 43/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 44/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 45/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 46/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0179\n",
            "Epoch 47/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 48/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 49/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 50/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 51/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 52/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 53/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 54/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 55/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 56/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 57/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 58/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 59/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 60/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 61/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0180\n",
            "Epoch 62/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 63/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 64/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 65/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0182\n",
            "Epoch 66/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 67/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 68/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 69/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0181\n",
            "Epoch 70/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 71/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 72/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 73/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0181\n",
            "Epoch 74/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0179\n",
            "Epoch 75/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 76/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 77/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 78/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0179\n",
            "Epoch 79/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 80/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "Epoch 81/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 82/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 83/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0183\n",
            "Epoch 84/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 85/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 86/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "Epoch 87/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 88/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 89/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 90/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 91/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0179\n",
            "Epoch 92/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "Epoch 93/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 94/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 95/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 96/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0184\n",
            "Epoch 97/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 98/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 99/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "Epoch 100/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 101/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 102/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 103/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "Epoch 104/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "Epoch 105/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 106/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 107/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 108/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 109/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 110/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0179\n",
            "Epoch 111/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 112/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 113/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 114/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 115/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 116/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 117/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 118/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 119/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "Epoch 120/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0179\n",
            "Epoch 121/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "Epoch 122/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 123/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 124/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 125/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 126/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0179\n",
            "Epoch 127/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 128/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 129/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0179\n",
            "Epoch 130/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 131/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "Epoch 132/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 133/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0179\n",
            "Epoch 134/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 135/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 136/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 137/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 138/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 139/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0175\n",
            "Epoch 140/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0179\n",
            "Epoch 141/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0177\n",
            "Epoch 142/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0180\n",
            "Epoch 143/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0177\n",
            "Epoch 144/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0179\n",
            "Epoch 145/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0179\n",
            "Epoch 146/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0183\n",
            "Epoch 147/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0187\n",
            "Epoch 148/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0179\n",
            "Epoch 149/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 150/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 151/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 152/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 153/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 154/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 155/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0179\n",
            "Epoch 156/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 157/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 158/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 159/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 160/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 161/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 162/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 163/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 164/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 165/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 166/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 167/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 168/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 169/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0190\n",
            "Epoch 170/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 171/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0186\n",
            "Epoch 172/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 173/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 174/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0184\n",
            "Epoch 175/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "Epoch 176/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0180\n",
            "Epoch 177/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 178/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0180\n",
            "Epoch 179/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "Epoch 180/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0179\n",
            "Epoch 181/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "Epoch 182/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 183/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 184/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 185/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 186/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0180\n",
            "Epoch 187/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 188/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 189/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 190/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 191/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0181\n",
            "Epoch 192/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0181\n",
            "Epoch 193/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 194/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 195/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 196/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 197/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0182\n",
            "Epoch 198/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 199/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0179\n",
            "Epoch 200/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0180\n",
            "Epoch 201/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0180\n",
            "Epoch 202/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 203/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 204/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 205/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 206/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 207/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 208/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 209/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 210/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0179\n",
            "Epoch 211/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 212/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0181\n",
            "Epoch 213/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 214/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 215/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 216/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 217/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 218/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0180\n",
            "Epoch 219/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 220/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0182\n",
            "Epoch 221/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0175\n",
            "Epoch 222/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 223/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 224/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 225/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "Epoch 226/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 227/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 228/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0180\n",
            "Epoch 229/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 230/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 231/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n",
            "Epoch 232/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0181\n",
            "Epoch 233/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0184\n",
            "Epoch 234/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0179\n",
            "Epoch 235/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0179\n",
            "Epoch 236/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0180\n",
            "Epoch 237/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 238/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 239/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0177\n",
            "Epoch 240/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0177\n",
            "Epoch 241/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0176\n",
            "Epoch 242/250\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0179\n",
            "Epoch 243/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0186\n",
            "Epoch 244/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0182\n",
            "Epoch 245/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0179\n",
            "Epoch 246/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0178\n",
            "Epoch 247/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0178\n",
            "Epoch 248/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0178\n",
            "Epoch 249/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0178\n",
            "Epoch 250/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View training history\n",
        "plt.plot(history.history['loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "e9wcugdS2zyM",
        "outputId": "1f7d3942-7716-43c7-acb0-53916b128bcc"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fcf915e7fd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test model\n",
        "eval_predictions = flat_list(model.predict(eval_predictors))"
      ],
      "metadata": {
        "id": "F3hcZ9wt31pC"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse model quality vs mean \n",
        "rmse = np.sqrt(np.mean((eval_targets.values - eval_predictions)**2))\n",
        "print('LinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "avg = np.mean(train_targets)\n",
        "\n",
        "rmse = np.sqrt(np.mean((eval_targets.values - avg)**2))\n",
        "print('Using the training data mean of {0} would have has resulted in a RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iYPVeVC7KYR",
        "outputId": "1eeac253-33e4-4dbb-baee-4ebf845186bc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression has RMSE of 0.13096232571629665\n",
            "Using the training data mean of 0.5156161260806462 would have has resulted in a RMSE of 0.1805106219054207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "test = pd.read_csv('https://raw.githubusercontent.com/MattIzon/16010269_DataAnalytics/main/LR/Normalised/test_set.csv')\n",
        "test_predictors = test[columns[0:qty_predictors]]\n",
        "normalise_w_params(test_predictors, scale_params, columns[0:qty_predictors])\n",
        "\n",
        "test_predictions = pd.DataFrame(flat_list(model.predict(test_predictors)), columns=['crime_count'])\n",
        "denormalise(test_predictions, scale_params, ['crime_count'])\n",
        "test_targets = test[columns[qty_predictors]]\n",
        "\n",
        "results = pd.DataFrame()\n",
        "results['predicted'] = test_predictions\n",
        "results['actual'] = test_targets\n",
        "results['error_squared'] = (results['predicted'] - results['actual']) ** 2\n",
        "print(results)\n",
        "\n",
        "print('The RMSE on the 5 test values is {}.'.format(np.sqrt(np.mean(results.error_squared))))\n",
        "print()"
      ],
      "metadata": {
        "id": "jsSl4tvr2aNX",
        "outputId": "42545949-c8de-49e7-b2a5-86c5a91af12b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    predicted  actual  error_squared\n",
            "0  770.862549     726    2012.648287\n",
            "1  641.269348     626     233.152993\n",
            "2  719.585815     732     154.111979\n",
            "3  707.862366     735     736.451194\n",
            "4  787.518677     794      42.007551\n",
            "The RMSE on the 5 test values is 25.21258417457904.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    }
  ]
}
