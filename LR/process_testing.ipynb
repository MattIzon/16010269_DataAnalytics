{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO5efMf0UP+UevonTN1Q5hD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MattIzon/16010269_DataAnalytics/blob/main/LR/process_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression Test Model\n",
        "All models have been useless. I suspect either my method for producing models is incorrect or my method for evaluating models is incorrect.\n",
        "\n",
        "This model is operating on perfectly linear data. In theory the model should be perfect"
      ],
      "metadata": {
        "id": "_364iE3AwpA-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J9vp7tzGf3eA"
      },
      "outputs": [],
      "source": [
        "# Set-up\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame(np.random.randint(0,100,size=(1000, 4)), columns=list('ABCD'))\n",
        "data['Z'] = (data.A * 0.5) + (data.B * 0.2) + (data.C * -0.87) + (data.D * -0.1) + 5\n",
        "data"
      ],
      "metadata": {
        "id": "bs_BolkcBckJ",
        "outputId": "47bc430c-f6dc-4ea8-850c-db8f6ee5dc8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      A   B   C   D      Z\n",
              "0    87  46  65  93  -8.15\n",
              "1    69  72  41  69  11.33\n",
              "2    63   9  15  98  15.45\n",
              "3    18  82  14  37  14.52\n",
              "4    55  46  76   8 -25.22\n",
              "..   ..  ..  ..  ..    ...\n",
              "995  43  25  62  26 -25.04\n",
              "996  12  29   3   8  13.39\n",
              "997  48  68  16  51  23.58\n",
              "998  87   0  63  88 -15.11\n",
              "999  91  23  30  52  23.80\n",
              "\n",
              "[1000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ff8b696-fd6e-4c23-948c-8aa304c4e9e1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>Z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>87</td>\n",
              "      <td>46</td>\n",
              "      <td>65</td>\n",
              "      <td>93</td>\n",
              "      <td>-8.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69</td>\n",
              "      <td>72</td>\n",
              "      <td>41</td>\n",
              "      <td>69</td>\n",
              "      <td>11.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>63</td>\n",
              "      <td>9</td>\n",
              "      <td>15</td>\n",
              "      <td>98</td>\n",
              "      <td>15.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18</td>\n",
              "      <td>82</td>\n",
              "      <td>14</td>\n",
              "      <td>37</td>\n",
              "      <td>14.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>55</td>\n",
              "      <td>46</td>\n",
              "      <td>76</td>\n",
              "      <td>8</td>\n",
              "      <td>-25.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>43</td>\n",
              "      <td>25</td>\n",
              "      <td>62</td>\n",
              "      <td>26</td>\n",
              "      <td>-25.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>12</td>\n",
              "      <td>29</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>13.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>48</td>\n",
              "      <td>68</td>\n",
              "      <td>16</td>\n",
              "      <td>51</td>\n",
              "      <td>23.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>87</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>88</td>\n",
              "      <td>-15.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>91</td>\n",
              "      <td>23</td>\n",
              "      <td>30</td>\n",
              "      <td>52</td>\n",
              "      <td>23.80</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ff8b696-fd6e-4c23-948c-8aa304c4e9e1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ff8b696-fd6e-4c23-948c-8aa304c4e9e1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ff8b696-fd6e-4c23-948c-8aa304c4e9e1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomised = data.iloc[np.random.permutation(len(data))]"
      ],
      "metadata": {
        "id": "8TXqCBaEgZCw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictors = randomised.iloc[:,0:4]\n",
        "targets = randomised.iloc[:,4]\n",
        "train_size = int(len(randomised)*0.8)\n",
        "qty_predictors = 4\n",
        "qty_targets = 1"
      ],
      "metadata": {
        "id": "Z2KCqEQpiMlT"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Design model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(qty_targets, input_shape=[qty_predictors]))\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.01))\n"
      ],
      "metadata": {
        "id": "vjj8Be7yqkLH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVJsFwGFziXv",
        "outputId": "3b2f221e-62a4-4766-e05d-2f9e765b4ffc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5\n",
            "Trainable params: 5\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "history = model.fit(predictors.iloc[0:train_size], targets.iloc[0:train_size], epochs=250)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2UP_cSK0QnO",
        "outputId": "19386af7-485d-409a-9840-5575f7b056aa"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 5175.0991\n",
            "Epoch 2/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 3719.5332\n",
            "Epoch 3/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 2627.9658\n",
            "Epoch 4/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1791.4272\n",
            "Epoch 5/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1181.0802\n",
            "Epoch 6/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 752.4044\n",
            "Epoch 7/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 466.7664\n",
            "Epoch 8/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 276.2528\n",
            "Epoch 9/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 159.3870\n",
            "Epoch 10/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 88.0722\n",
            "Epoch 11/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 48.0739\n",
            "Epoch 12/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 25.5499\n",
            "Epoch 13/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 13.5231\n",
            "Epoch 14/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 7.3630\n",
            "Epoch 15/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 4.1752\n",
            "Epoch 16/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 2.6949\n",
            "Epoch 17/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.9627\n",
            "Epoch 18/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.6252\n",
            "Epoch 19/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.4402\n",
            "Epoch 20/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 1.3537\n",
            "Epoch 21/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.3136\n",
            "Epoch 22/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 1.2925\n",
            "Epoch 23/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.2803\n",
            "Epoch 24/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.2675\n",
            "Epoch 25/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.2559\n",
            "Epoch 26/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.2510\n",
            "Epoch 27/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.2388\n",
            "Epoch 28/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.2307\n",
            "Epoch 29/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.2257\n",
            "Epoch 30/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.2087\n",
            "Epoch 31/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.2021\n",
            "Epoch 32/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.1896\n",
            "Epoch 33/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.1838\n",
            "Epoch 34/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.1773\n",
            "Epoch 35/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 1.1608\n",
            "Epoch 36/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.1593\n",
            "Epoch 37/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.1471\n",
            "Epoch 38/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.1382\n",
            "Epoch 39/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.1215\n",
            "Epoch 40/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.1112\n",
            "Epoch 41/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.1011\n",
            "Epoch 42/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 1.0943\n",
            "Epoch 43/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.0791\n",
            "Epoch 44/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 1.0667\n",
            "Epoch 45/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.0696\n",
            "Epoch 46/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.0498\n",
            "Epoch 47/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.0356\n",
            "Epoch 48/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.0254\n",
            "Epoch 49/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.0135\n",
            "Epoch 50/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.0228\n",
            "Epoch 51/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.9904\n",
            "Epoch 52/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.9961\n",
            "Epoch 53/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.9705\n",
            "Epoch 54/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.9640\n",
            "Epoch 55/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.9593\n",
            "Epoch 56/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.9297\n",
            "Epoch 57/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.9219\n",
            "Epoch 58/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.9161\n",
            "Epoch 59/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.8963\n",
            "Epoch 60/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.8881\n",
            "Epoch 61/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.8789\n",
            "Epoch 62/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.8620\n",
            "Epoch 63/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.8559\n",
            "Epoch 64/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.8410\n",
            "Epoch 65/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.8387\n",
            "Epoch 66/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.8181\n",
            "Epoch 67/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.8058\n",
            "Epoch 68/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.7968\n",
            "Epoch 69/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.7817\n",
            "Epoch 70/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.7915\n",
            "Epoch 71/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.7552\n",
            "Epoch 72/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.7464\n",
            "Epoch 73/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.7304\n",
            "Epoch 74/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.7387\n",
            "Epoch 75/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.7148\n",
            "Epoch 76/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.7007\n",
            "Epoch 77/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6844\n",
            "Epoch 78/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.6691\n",
            "Epoch 79/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.6579\n",
            "Epoch 80/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.6495\n",
            "Epoch 81/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6370\n",
            "Epoch 82/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.6222\n",
            "Epoch 83/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.6149\n",
            "Epoch 84/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.6174\n",
            "Epoch 85/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5922\n",
            "Epoch 86/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.5822\n",
            "Epoch 87/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5891\n",
            "Epoch 88/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5572\n",
            "Epoch 89/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5458\n",
            "Epoch 90/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5426\n",
            "Epoch 91/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.5257\n",
            "Epoch 92/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.5117\n",
            "Epoch 93/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.4993\n",
            "Epoch 94/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.4887\n",
            "Epoch 95/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.4797\n",
            "Epoch 96/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.4709\n",
            "Epoch 97/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.4627\n",
            "Epoch 98/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4525\n",
            "Epoch 99/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.4375\n",
            "Epoch 100/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4282\n",
            "Epoch 101/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.4293\n",
            "Epoch 102/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.4034\n",
            "Epoch 103/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.3988\n",
            "Epoch 104/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.3907\n",
            "Epoch 105/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.3839\n",
            "Epoch 106/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.3743\n",
            "Epoch 107/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.3587\n",
            "Epoch 108/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3533\n",
            "Epoch 109/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3406\n",
            "Epoch 110/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3343\n",
            "Epoch 111/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.3223\n",
            "Epoch 112/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.3147\n",
            "Epoch 113/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.3047\n",
            "Epoch 114/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.2933\n",
            "Epoch 115/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.2878\n",
            "Epoch 116/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.2785\n",
            "Epoch 117/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.2724\n",
            "Epoch 118/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2632\n",
            "Epoch 119/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.2551\n",
            "Epoch 120/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.2482\n",
            "Epoch 121/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2381\n",
            "Epoch 122/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.2354\n",
            "Epoch 123/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.2276\n",
            "Epoch 124/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.2175\n",
            "Epoch 125/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.2093\n",
            "Epoch 126/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.2049\n",
            "Epoch 127/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.1989\n",
            "Epoch 128/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1963\n",
            "Epoch 129/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.1860\n",
            "Epoch 130/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1770\n",
            "Epoch 131/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.1714\n",
            "Epoch 132/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.1728\n",
            "Epoch 133/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.1619\n",
            "Epoch 134/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.1548\n",
            "Epoch 135/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.1491\n",
            "Epoch 136/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.1418\n",
            "Epoch 137/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.1366\n",
            "Epoch 138/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.1327\n",
            "Epoch 139/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.1267\n",
            "Epoch 140/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.1269\n",
            "Epoch 141/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.1226\n",
            "Epoch 142/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.1112\n",
            "Epoch 143/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.1089\n",
            "Epoch 144/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1082\n",
            "Epoch 145/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0993\n",
            "Epoch 146/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0942\n",
            "Epoch 147/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.0923\n",
            "Epoch 148/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0869\n",
            "Epoch 149/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0820\n",
            "Epoch 150/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0796\n",
            "Epoch 151/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0753\n",
            "Epoch 152/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0762\n",
            "Epoch 153/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0691\n",
            "Epoch 154/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0673\n",
            "Epoch 155/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.0652\n",
            "Epoch 156/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.0594\n",
            "Epoch 157/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0575\n",
            "Epoch 158/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.0548\n",
            "Epoch 159/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.0546\n",
            "Epoch 160/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0499\n",
            "Epoch 161/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0463\n",
            "Epoch 162/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0474\n",
            "Epoch 163/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.0443\n",
            "Epoch 164/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.0396\n",
            "Epoch 165/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.0380\n",
            "Epoch 166/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0360\n",
            "Epoch 167/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0344\n",
            "Epoch 168/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0312\n",
            "Epoch 169/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0296\n",
            "Epoch 170/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0280\n",
            "Epoch 171/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0267\n",
            "Epoch 172/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0249\n",
            "Epoch 173/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.0232\n",
            "Epoch 174/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0220\n",
            "Epoch 175/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0203\n",
            "Epoch 176/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0194\n",
            "Epoch 177/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0193\n",
            "Epoch 178/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0186\n",
            "Epoch 179/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0165\n",
            "Epoch 180/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0147\n",
            "Epoch 181/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.0137\n",
            "Epoch 182/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0133\n",
            "Epoch 183/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0122\n",
            "Epoch 184/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0120\n",
            "Epoch 185/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.0110\n",
            "Epoch 186/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0099\n",
            "Epoch 187/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.0092\n",
            "Epoch 188/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.0090\n",
            "Epoch 189/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0081\n",
            "Epoch 190/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 191/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 192/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 193/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0060\n",
            "Epoch 194/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.0058\n",
            "Epoch 195/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0050\n",
            "Epoch 196/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0055\n",
            "Epoch 197/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0048\n",
            "Epoch 198/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0040\n",
            "Epoch 199/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0037\n",
            "Epoch 200/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.0033\n",
            "Epoch 201/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0030\n",
            "Epoch 202/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.0028\n",
            "Epoch 203/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0025\n",
            "Epoch 204/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0023\n",
            "Epoch 205/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0021\n",
            "Epoch 206/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 207/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 208/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0017\n",
            "Epoch 209/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 210/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 211/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0012\n",
            "Epoch 212/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.0011\n",
            "Epoch 213/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 9.7425e-04\n",
            "Epoch 214/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 8.7428e-04\n",
            "Epoch 215/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 8.1189e-04\n",
            "Epoch 216/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 7.2980e-04\n",
            "Epoch 217/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 6.6882e-04\n",
            "Epoch 218/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 5.8609e-04\n",
            "Epoch 219/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 5.3625e-04\n",
            "Epoch 220/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 4.7953e-04\n",
            "Epoch 221/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 4.1337e-04\n",
            "Epoch 222/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 3.9672e-04\n",
            "Epoch 223/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 3.3864e-04\n",
            "Epoch 224/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 3.0176e-04\n",
            "Epoch 225/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 2.7088e-04\n",
            "Epoch 226/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 2.2814e-04\n",
            "Epoch 227/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 2.0671e-04\n",
            "Epoch 228/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.8915e-04\n",
            "Epoch 229/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.9072e-04\n",
            "Epoch 230/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 1.4122e-04\n",
            "Epoch 231/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.5323e-04\n",
            "Epoch 232/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.1316e-04\n",
            "Epoch 233/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 9.2592e-05\n",
            "Epoch 234/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 8.3316e-05\n",
            "Epoch 235/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 7.4276e-05\n",
            "Epoch 236/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 6.5036e-05\n",
            "Epoch 237/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 5.3543e-05\n",
            "Epoch 238/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 4.6823e-05\n",
            "Epoch 239/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 4.1069e-05\n",
            "Epoch 240/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 3.7165e-05\n",
            "Epoch 241/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 3.5116e-05\n",
            "Epoch 242/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 2.7572e-05\n",
            "Epoch 243/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 2.3042e-05\n",
            "Epoch 244/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 2.0985e-05\n",
            "Epoch 245/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.7331e-05\n",
            "Epoch 246/250\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 1.5518e-05\n",
            "Epoch 247/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.2673e-05\n",
            "Epoch 248/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.1096e-05\n",
            "Epoch 249/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 9.1480e-06\n",
            "Epoch 250/250\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 7.8316e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View training history\n",
        "plt.plot(history.history['loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "e9wcugdS2zyM",
        "outputId": "1c1c2a33-6565-407a-cc36-6116d2d5ded8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f240ca18ad0>]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test model\n",
        "model_test = model.predict(predictors.iloc[train_size:])"
      ],
      "metadata": {
        "id": "F3hcZ9wt31pC"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse model quality vs mean \n",
        "rmse = np.sqrt(np.mean((targets[train_size:].values - model_test)**2))\n",
        "print('LinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "avg = np.mean(data['Z'][:train_size])\n",
        "\n",
        "rmse = np.sqrt(np.mean((targets[train_size:].values - avg)**2))\n",
        "print('Using the training data mean of {0} would have has resulted in a RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iYPVeVC7KYR",
        "outputId": "34e1baa9-a5cf-453c-9833-df5283d6cf8b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression has RMSE of 40.22017478120073\n",
            "Using the training data mean of -8.568125 would have has resulted in a RMSE of 28.452104737885826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy = pd.DataFrame(np.random.randint(100,200,size=(1, 4)), columns=list('ABCD'))\n",
        "print(model.predict(dummy))\n",
        "print((dummy.A * 0.5) + (dummy.B * 0.2) + (dummy.C * -0.87) + (dummy.D * -0.1) + 5)\n"
      ],
      "metadata": {
        "id": "56LmZ34kEfDM",
        "outputId": "f16826fd-1720-4de1-e42c-85caa5eb97cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-33.84829]]\n",
            "0   -33.86\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The predicted value is perfect.\n",
        "The evaluation indicates otherwise. There must be an error in the evaluation"
      ],
      "metadata": {
        "id": "rGSn8kSeH6pk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = targets.iloc[train_size:].values\n",
        "b = model_test\n",
        "print(a)\n",
        "print(b)\n",
        "print(a - b)"
      ],
      "metadata": {
        "id": "Z0-_4CRkIgA5",
        "outputId": "8835ca8a-5dee-4dd4-d0a4-d5e46b75f9e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-39.44  13.23 -32.23 -36.89  23.63 -19.7  -20.11 -56.29  21.83  -4.76\n",
            "  -1.96 -10.05 -35.15 -49.66  37.93   1.07 -13.72  15.01 -20.97 -11.13\n",
            "  12.99  56.06 -12.18  -4.61 -59.66 -32.84   8.58 -27.78  15.31 -54.64\n",
            " -11.68 -35.45 -43.21 -17.77  21.77  48.06 -16.45 -50.71 -29.87  -7.09\n",
            " -30.68  35.41 -15.11  40.91 -70.83  25.73 -43.04 -13.82  14.17 -33.38\n",
            "  33.6  -26.07  46.72 -10.94 -18.91  39.4  -33.17 -20.8  -44.9  -13.35\n",
            "  12.89 -48.02  14.79 -13.3   -4.6   10.76 -16.73  -9.89 -13.27 -30.84\n",
            "  35.88  -6.74  20.65 -33.43  23.87  -6.94 -27.12 -58.99 -55.29 -67.86\n",
            "  12.9  -62.1  -71.01 -44.67  -4.08 -65.1    6.89  23.61 -49.95 -26.3\n",
            " -15.77  20.71   0.44  -2.05 -48.81  -4.34 -63.21   0.55  12.63 -34.16\n",
            "  38.78  23.38 -30.98  15.23 -44.92   0.41  -3.22  31.39   3.4  -69.1\n",
            "  24.65   5.58 -42.04  11.31 -34.67 -71.82  34.03 -27.44  -7.36 -27.19\n",
            "  -7.98   5.29 -28.01  -4.99 -22.13 -15.13   3.63 -12.34   2.91   3.54\n",
            "  39.3    6.7   -8.13  12.76 -11.34  -4.29 -46.07  19.77  25.16  20.95\n",
            " -26.35 -30.13  22.16   9.35 -43.84 -36.77  10.24 -19.81   8.99   9.66\n",
            "  11.33   3.11  38.7    5.39 -47.12 -31.71 -51.24  -0.14  -0.65   8.01\n",
            " -50.96  14.44   4.59 -24.3  -12.11  -2.04 -20.84  15.66   3.52  12.13\n",
            " -12.02  -5.78  52.03 -37.54  10.98 -22.08  -1.07   6.25 -25.07  17.92\n",
            "  45.09 -28.93 -16.26  32.99 -59.61  15.94  -5.65 -12.05   8.94 -38.76\n",
            " -15.3  -36.27  24.26  11.95  22.51 -23.56  25.98 -33.7  -13.82 -48.23]\n",
            "[[-39.437996  ]\n",
            " [ 13.227201  ]\n",
            " [-32.231598  ]\n",
            " [-36.89103   ]\n",
            " [ 23.630846  ]\n",
            " [-19.70543   ]\n",
            " [-20.111897  ]\n",
            " [-56.2892    ]\n",
            " [ 21.831778  ]\n",
            " [ -4.7623353 ]\n",
            " [ -1.958828  ]\n",
            " [-10.050762  ]\n",
            " [-35.14981   ]\n",
            " [-49.659317  ]\n",
            " [ 37.929886  ]\n",
            " [  1.0732718 ]\n",
            " [-13.723009  ]\n",
            " [ 15.006046  ]\n",
            " [-20.973183  ]\n",
            " [-11.135349  ]\n",
            " [ 12.98863   ]\n",
            " [ 56.06059   ]\n",
            " [-12.179234  ]\n",
            " [ -4.610394  ]\n",
            " [-59.66145   ]\n",
            " [-32.841442  ]\n",
            " [  8.577553  ]\n",
            " [-27.783985  ]\n",
            " [ 15.30595   ]\n",
            " [-54.640373  ]\n",
            " [-11.686241  ]\n",
            " [-35.44903   ]\n",
            " [-43.210743  ]\n",
            " [-17.77613   ]\n",
            " [ 21.769188  ]\n",
            " [ 48.055443  ]\n",
            " [-16.455034  ]\n",
            " [-50.7119    ]\n",
            " [-29.87526   ]\n",
            " [ -7.0934176 ]\n",
            " [-30.677032  ]\n",
            " [ 35.41024   ]\n",
            " [-15.109766  ]\n",
            " [ 40.907124  ]\n",
            " [-70.83265   ]\n",
            " [ 25.729843  ]\n",
            " [-43.040874  ]\n",
            " [-13.823036  ]\n",
            " [ 14.1690445 ]\n",
            " [-33.37943   ]\n",
            " [ 33.59874   ]\n",
            " [-26.07323   ]\n",
            " [ 46.716442  ]\n",
            " [-10.942389  ]\n",
            " [-18.907465  ]\n",
            " [ 39.397152  ]\n",
            " [-33.17107   ]\n",
            " [-20.804977  ]\n",
            " [-44.898453  ]\n",
            " [-13.350624  ]\n",
            " [ 12.888998  ]\n",
            " [-48.017654  ]\n",
            " [ 14.7854    ]\n",
            " [-13.301268  ]\n",
            " [ -4.602366  ]\n",
            " [ 10.762919  ]\n",
            " [-16.73417   ]\n",
            " [ -9.893871  ]\n",
            " [-13.267916  ]\n",
            " [-30.841755  ]\n",
            " [ 35.876408  ]\n",
            " [ -6.7389283 ]\n",
            " [ 20.649014  ]\n",
            " [-33.43122   ]\n",
            " [ 23.871222  ]\n",
            " [ -6.938577  ]\n",
            " [-27.120281  ]\n",
            " [-58.9939    ]\n",
            " [-55.28954   ]\n",
            " [-67.86232   ]\n",
            " [ 12.896126  ]\n",
            " [-62.10078   ]\n",
            " [-71.0113    ]\n",
            " [-44.672325  ]\n",
            " [ -4.0825553 ]\n",
            " [-65.103905  ]\n",
            " [  6.889519  ]\n",
            " [ 23.610134  ]\n",
            " [-49.95108   ]\n",
            " [-26.30251   ]\n",
            " [-15.769434  ]\n",
            " [ 20.70865   ]\n",
            " [  0.44121647]\n",
            " [ -2.05134   ]\n",
            " [-48.81123   ]\n",
            " [ -4.3374953 ]\n",
            " [-63.212376  ]\n",
            " [  0.5471196 ]\n",
            " [ 12.628195  ]\n",
            " [-34.16359   ]\n",
            " [ 38.78023   ]\n",
            " [ 23.380978  ]\n",
            " [-30.980637  ]\n",
            " [ 15.222483  ]\n",
            " [-44.919487  ]\n",
            " [  0.40711832]\n",
            " [ -3.219028  ]\n",
            " [ 31.391975  ]\n",
            " [  3.3946857 ]\n",
            " [-69.10565   ]\n",
            " [ 24.650599  ]\n",
            " [  5.582004  ]\n",
            " [-42.041832  ]\n",
            " [ 11.31102   ]\n",
            " [-34.67038   ]\n",
            " [-71.82052   ]\n",
            " [ 34.027477  ]\n",
            " [-27.441315  ]\n",
            " [ -7.3573318 ]\n",
            " [-27.187454  ]\n",
            " [ -7.9834313 ]\n",
            " [  5.2893434 ]\n",
            " [-28.014297  ]\n",
            " [ -4.993954  ]\n",
            " [-22.127346  ]\n",
            " [-15.131548  ]\n",
            " [  3.6263587 ]\n",
            " [-12.33947   ]\n",
            " [  2.9068258 ]\n",
            " [  3.5374289 ]\n",
            " [ 39.298065  ]\n",
            " [  6.6924305 ]\n",
            " [ -8.129631  ]\n",
            " [ 12.758938  ]\n",
            " [-11.344452  ]\n",
            " [ -4.29032   ]\n",
            " [-46.070824  ]\n",
            " [ 19.768246  ]\n",
            " [ 25.15924   ]\n",
            " [ 20.949364  ]\n",
            " [-26.352257  ]\n",
            " [-30.134876  ]\n",
            " [ 22.162119  ]\n",
            " [  9.348228  ]\n",
            " [-43.844334  ]\n",
            " [-36.772934  ]\n",
            " [ 10.23952   ]\n",
            " [-19.812075  ]\n",
            " [  8.987176  ]\n",
            " [  9.659912  ]\n",
            " [ 11.330633  ]\n",
            " [  3.1086752 ]\n",
            " [ 38.6989    ]\n",
            " [  5.3851237 ]\n",
            " [-47.121105  ]\n",
            " [-31.712242  ]\n",
            " [-51.242554  ]\n",
            " [ -0.1389761 ]\n",
            " [ -0.65195656]\n",
            " [  8.012178  ]\n",
            " [-50.961098  ]\n",
            " [ 14.436413  ]\n",
            " [  4.5905423 ]\n",
            " [-24.302687  ]\n",
            " [-12.111538  ]\n",
            " [ -2.0374556 ]\n",
            " [-20.84003   ]\n",
            " [ 15.657936  ]\n",
            " [  3.5203676 ]\n",
            " [ 12.126991  ]\n",
            " [-12.022581  ]\n",
            " [ -5.780398  ]\n",
            " [ 52.028313  ]\n",
            " [-37.54107   ]\n",
            " [ 10.980589  ]\n",
            " [-22.083221  ]\n",
            " [ -1.0740609 ]\n",
            " [  6.2477584 ]\n",
            " [-25.075033  ]\n",
            " [ 17.916897  ]\n",
            " [ 45.086594  ]\n",
            " [-28.933178  ]\n",
            " [-16.259327  ]\n",
            " [ 32.99115   ]\n",
            " [-59.61246   ]\n",
            " [ 15.941185  ]\n",
            " [ -5.650268  ]\n",
            " [-12.046371  ]\n",
            " [  8.93799   ]\n",
            " [-38.75913   ]\n",
            " [-15.29858   ]\n",
            " [-36.27127   ]\n",
            " [ 24.257137  ]\n",
            " [ 11.946735  ]\n",
            " [ 22.511572  ]\n",
            " [-23.560293  ]\n",
            " [ 25.979239  ]\n",
            " [-33.70248   ]\n",
            " [-13.819111  ]\n",
            " [-48.23083   ]]\n",
            "[[-2.00408936e-03  5.26679959e+01  7.20799591e+00 ...  5.73799591e+00\n",
            "   2.56179959e+01 -8.79200409e+00]\n",
            " [-5.26672015e+01  2.79853821e-03 -4.54572015e+01 ... -4.69272015e+01\n",
            "  -2.70472015e+01 -6.14572015e+01]\n",
            " [-7.20840210e+00  4.54615979e+01  1.59790039e-03 ... -1.46840210e+00\n",
            "   1.84115979e+01 -1.59984021e+01]\n",
            " ...\n",
            " [-5.73751968e+00  4.69324803e+01  1.47248032e+00 ...  2.48031616e-03\n",
            "   1.98824803e+01 -1.45275197e+01]\n",
            " [-2.56208891e+01  2.70491109e+01 -1.84108891e+01 ... -1.98808891e+01\n",
            "  -8.89129639e-04 -3.44108891e+01]\n",
            " [ 8.79083115e+00  6.14608311e+01  1.60008311e+01 ...  1.45308311e+01\n",
            "   3.44108311e+01  8.31146240e-04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model_test data is the wrong shape"
      ],
      "metadata": {
        "id": "mQxPl_cVODGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flat_list(nested_list):\n",
        "  return [value for sublist in nested_list for value in sublist]\n",
        "print(np.sqrt(np.mean((targets[train_size:].values - flat_list(model_test)) **2)))"
      ],
      "metadata": {
        "id": "7BVKp-1MJnFU",
        "outputId": "ea6f3170-3ccb-442b-d393-1ec8e253c220",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0025908522175767017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse model quality vs mean \n",
        "rmse = np.sqrt(np.mean((targets[train_size:].values - flat_list(model_test))**2))\n",
        "print('LinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "avg = np.mean(data['Z'][:train_size])\n",
        "\n",
        "rmse = np.sqrt(np.mean((targets[train_size:].values - avg)**2))\n",
        "print('Using the training data mean of {0} would have has resulted in a RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "Nc18xQwpM0sx",
        "outputId": "7c563f53-9e4a-4f27-f7f2-2dda39cf16aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression has RMSE of 0.0025908522175767017\n",
            "Using the training data mean of -8.568125 would have has resulted in a RMSE of 28.452104737885826\n"
          ]
        }
      ]
    }
  ]
}