{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MattIzon/16010269_DataAnalytics/blob/main/LR/model2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression Model 2\n",
        "Predictors: day_of_week (linear organisation based on crime_count mean)\n",
        "\n",
        "Mon 3,\n",
        "Tue 7,\n",
        "Wed 5,\n",
        "Thu 4,\n",
        "Fri 1,\n",
        "Sat 2,\n",
        "Sun 6,"
      ],
      "metadata": {
        "id": "_364iE3AwpA-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J9vp7tzGf3eA"
      },
      "outputs": [],
      "source": [
        "# Set-up\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "def flat_list(nested_list):\n",
        "  return [value for sublist in nested_list for value in sublist]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/MattIzon/16010269_DataAnalytics/main/LR/LR2.csv')"
      ],
      "metadata": {
        "id": "FgJ4u-ehgEQX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "randomised = data.iloc[np.random.permutation(len(data))]"
      ],
      "metadata": {
        "id": "8TXqCBaEgZCw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictors = randomised.iloc[:,0]\n",
        "targets = randomised.iloc[:,1]\n",
        "train_size = int(len(randomised)*0.8)\n",
        "qty_predictors = 1\n",
        "qty_targets = 1"
      ],
      "metadata": {
        "id": "Z2KCqEQpiMlT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Design model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(qty_targets, input_shape=[qty_predictors]))\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.01))"
      ],
      "metadata": {
        "id": "vjj8Be7yqkLH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVJsFwGFziXv",
        "outputId": "0dea29a6-69d4-4555-bb74-2ec49c44f106"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "history = model.fit(predictors.iloc[0:train_size], targets.iloc[0:train_size], epochs=250)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2UP_cSK0QnO",
        "outputId": "2e4417d7-8641-450f-d144-5273e8ad2ac1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "44/44 [==============================] - 1s 2ms/step - loss: 15.3265\n",
            "Epoch 2/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 4.0626\n",
            "Epoch 3/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.7159\n",
            "Epoch 4/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1222\n",
            "Epoch 5/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0645\n",
            "Epoch 6/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 7/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0591\n",
            "Epoch 8/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0576\n",
            "Epoch 9/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0560\n",
            "Epoch 10/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0544\n",
            "Epoch 11/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0531\n",
            "Epoch 12/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0518\n",
            "Epoch 13/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0506\n",
            "Epoch 14/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0495\n",
            "Epoch 15/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0486\n",
            "Epoch 16/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0477\n",
            "Epoch 17/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0470\n",
            "Epoch 18/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0462\n",
            "Epoch 19/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0457\n",
            "Epoch 20/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0452\n",
            "Epoch 21/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0448\n",
            "Epoch 22/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0444\n",
            "Epoch 23/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0441\n",
            "Epoch 24/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0438\n",
            "Epoch 25/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 26/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0435\n",
            "Epoch 27/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0434\n",
            "Epoch 28/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0432\n",
            "Epoch 29/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 30/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 31/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0430\n",
            "Epoch 32/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0430\n",
            "Epoch 33/250\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0430\n",
            "Epoch 34/250\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0429\n",
            "Epoch 35/250\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0429\n",
            "Epoch 36/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0429\n",
            "Epoch 37/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0430\n",
            "Epoch 38/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0429\n",
            "Epoch 39/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 40/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0430\n",
            "Epoch 41/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 42/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0429\n",
            "Epoch 43/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 44/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0429\n",
            "Epoch 45/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 46/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0429\n",
            "Epoch 47/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 48/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 49/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 50/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0429\n",
            "Epoch 51/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 52/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0429\n",
            "Epoch 53/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 54/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 55/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 56/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 57/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 58/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0429\n",
            "Epoch 59/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0429\n",
            "Epoch 60/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 61/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 62/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 63/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 64/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 65/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 66/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0428\n",
            "Epoch 67/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 68/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 69/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 70/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 71/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 72/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0435\n",
            "Epoch 73/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 74/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 75/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 76/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 77/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0430\n",
            "Epoch 78/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 79/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 80/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 81/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 82/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 83/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 84/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 85/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 86/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0430\n",
            "Epoch 87/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 88/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 89/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0429\n",
            "Epoch 90/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0429\n",
            "Epoch 91/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 92/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 93/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 94/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 95/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 96/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 97/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 98/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 99/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 100/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 101/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0429\n",
            "Epoch 102/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 103/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 104/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 105/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 106/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 107/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0429\n",
            "Epoch 108/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 109/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 110/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 111/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 112/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 113/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 114/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 115/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 116/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0432\n",
            "Epoch 117/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 118/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0438\n",
            "Epoch 119/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0440\n",
            "Epoch 120/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 121/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 122/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 123/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 124/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 125/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 126/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 127/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 128/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 129/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 130/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0436\n",
            "Epoch 131/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0435\n",
            "Epoch 132/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0435\n",
            "Epoch 133/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0442\n",
            "Epoch 134/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0435\n",
            "Epoch 135/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0438\n",
            "Epoch 136/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 137/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0435\n",
            "Epoch 138/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 139/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0443\n",
            "Epoch 140/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 141/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0440\n",
            "Epoch 142/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0436\n",
            "Epoch 143/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0443\n",
            "Epoch 144/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0440\n",
            "Epoch 145/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 146/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0435\n",
            "Epoch 147/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 148/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0435\n",
            "Epoch 149/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0439\n",
            "Epoch 150/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 151/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 152/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0438\n",
            "Epoch 153/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 154/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 155/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0439\n",
            "Epoch 156/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0436\n",
            "Epoch 157/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0437\n",
            "Epoch 158/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 159/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0429\n",
            "Epoch 160/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 161/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 162/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0436\n",
            "Epoch 163/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0436\n",
            "Epoch 164/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 165/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0441\n",
            "Epoch 166/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0437\n",
            "Epoch 167/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0437\n",
            "Epoch 168/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 169/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0435\n",
            "Epoch 170/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0438\n",
            "Epoch 171/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 172/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0437\n",
            "Epoch 173/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0437\n",
            "Epoch 174/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0439\n",
            "Epoch 175/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 176/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 177/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0436\n",
            "Epoch 178/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 179/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0444\n",
            "Epoch 180/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 181/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 182/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0443\n",
            "Epoch 183/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 184/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0437\n",
            "Epoch 185/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0446\n",
            "Epoch 186/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0435\n",
            "Epoch 187/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 188/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0436\n",
            "Epoch 189/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0436\n",
            "Epoch 190/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0457\n",
            "Epoch 191/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0448\n",
            "Epoch 192/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0443\n",
            "Epoch 193/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0436\n",
            "Epoch 194/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0435\n",
            "Epoch 195/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0436\n",
            "Epoch 196/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0439\n",
            "Epoch 197/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0435\n",
            "Epoch 198/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0444\n",
            "Epoch 199/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 200/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 201/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0436\n",
            "Epoch 202/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 203/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 204/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0436\n",
            "Epoch 205/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0442\n",
            "Epoch 206/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0434\n",
            "Epoch 207/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0436\n",
            "Epoch 208/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 209/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 210/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 211/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0440\n",
            "Epoch 212/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0444\n",
            "Epoch 213/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0432\n",
            "Epoch 214/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0440\n",
            "Epoch 215/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0435\n",
            "Epoch 216/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 217/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0435\n",
            "Epoch 218/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 219/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 220/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0436\n",
            "Epoch 221/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0439\n",
            "Epoch 222/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 223/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0437\n",
            "Epoch 224/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0448\n",
            "Epoch 225/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 226/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 227/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0437\n",
            "Epoch 228/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0436\n",
            "Epoch 229/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0448\n",
            "Epoch 230/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 231/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0435\n",
            "Epoch 232/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0435\n",
            "Epoch 233/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0438\n",
            "Epoch 234/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 235/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 236/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0439\n",
            "Epoch 237/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 238/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0435\n",
            "Epoch 239/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 240/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0450\n",
            "Epoch 241/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 242/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 243/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0443\n",
            "Epoch 244/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 245/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 246/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0430\n",
            "Epoch 247/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 248/250\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0435\n",
            "Epoch 249/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0435\n",
            "Epoch 250/250\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View training history\n",
        "plt.plot(history.history['loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "e9wcugdS2zyM",
        "outputId": "2d87dc7b-241e-445c-a40d-ca74d41c6618"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe61e8a1d90>]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test model\n",
        "model_test = flat_list(model.predict(predictors.iloc[train_size:]))"
      ],
      "metadata": {
        "id": "F3hcZ9wt31pC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse model quality vs mean \n",
        "rmse = np.sqrt(np.mean((targets[train_size:].values - model_test)**2))\n",
        "print('LinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "avg = np.mean(data['crime_count'][:train_size])\n",
        "\n",
        "rmse = np.sqrt(np.mean((targets[train_size:].values - avg)**2))\n",
        "print('Using the training data mean of {0} would have has resulted in a RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iYPVeVC7KYR",
        "outputId": "734b29ff-3a40-4e6c-baa4-2173e2842ced"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression has RMSE of 0.19639220645580754\n",
            "Using the training data mean of 0.5080399258596116 would have has resulted in a RMSE of 0.19719710480227667\n"
          ]
        }
      ]
    }
  ]
}